{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter, IndexConverter\n",
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "from generate import gen_text_img\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "from models.densenet_ import DenseNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "#         #print('train_loader',len(train_loader))\n",
    "#         images = sample.images\n",
    "#         targets = sample.targets\n",
    "#         target_lengths = sample.target_lengths\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         # zero out gradients so we can accumulate new ones over batches\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # step 2. Get our inputs images ready for the network.\n",
    "#         images = images.to(device)\n",
    "#         # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "#         # Expected targets to have CPU Backend\n",
    "#         target_lengths = target_lengths.to(device)\n",
    "\n",
    "#         # step 3. Run out forward pass.\n",
    "#         log_probs = model(images)\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs targets ready for the network.\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        target_lengths = sample.target_lengths.to(device)\n",
    "        targets = sample.targets # Expected targets to have CPU Backend\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        images = sample.images\n",
    "        targets = targets.to(device)\n",
    "        log_probs = []\n",
    "        for image in images:\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            log_prob = model(image).squeeze(1)\n",
    "            log_probs.append(log_prob)\n",
    "        input_lengths = torch.IntTensor([i.size(0) for i in log_probs]).to(device)\n",
    "        log_probs = pad_sequence(log_probs.unsqueeze(0))\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "#         images = sample.images\n",
    "#         targets = sample.targets\n",
    "#         images = images.to(device)\n",
    "#         log_probs = model(images)\n",
    "#         preds = converter.best_path_decode(log_probs, strings=False)\n",
    "#         print(log_probs)\n",
    "#         print(preds)\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        if isinstance(images, tuple):\n",
    "            preds = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image)\n",
    "                preds.append(converter.best_path_decode(log_prob, strings=False))\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            print(pred)\n",
    "            print(target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# alphabet/alphabet_decode_5990.txt\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--max-epoch','100','--optimizer','rmsprop','--gpu-id','-1','--not-pretrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using model from scratch (random weights) 'densenet121'\n"
     ]
    }
   ],
   "source": [
    "global args, device\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "# model_params = {}\n",
    "# model_params['architecture'] = args.arch\n",
    "# model_params['num_classes'] = len(args.alphabet) + 1\n",
    "# model_params['mean'] = (0.5,)\n",
    "# model_params['std'] = (0.5,)\n",
    "# model_params['pretrained'] = args.pretrained\n",
    "# model = init_network(model_params)\n",
    "# model = model.to(device)\n",
    "model = DenseNet(img_height=32, drop_rate=0.2, num_classes=len(args.alphabet) + 1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=model.meta['mean'], std=model.meta['std'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe565431dd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe565458198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "\n",
    "num = 1000\n",
    "dev_num = int(num/10)\n",
    "use_file = 1\n",
    "text_length = -1\n",
    "font_size = 0\n",
    "font_id = 1\n",
    "space_width = 1\n",
    "text_color = '#282828'\n",
    "thread_count = 8\n",
    "\n",
    "random_skew = False\n",
    "skew_angle = 0\n",
    "random_blur = False\n",
    "blur = 0\n",
    "\n",
    "distorsion = 0\n",
    "background = 1\n",
    "\n",
    "text_meta, text_img = gen_text_img(num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "\n",
    "index_converter = IndexConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "train_dataset = InMemoryDigitsDataset(mode='train',text=text_meta,img=text_img,total=num,\n",
    "                                      transform=transform, converter = index_converter)\n",
    "dev_dataset = InMemoryDigitsDataset(mode='dev', text=dev_meta, img=dev_img, total=dev_num,\n",
    "                                    transform=transform, converter = index_converter)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=inmemory_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=inmemory_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "# for i in range(100):\n",
    "#     img, label = train_dataset.__getitem__(i)\n",
    "#     print(img.shape,label)\n",
    "plt.imshow(train_dataset.__getitem__(0)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6a19327fbdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# train for one epoch on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0c37264acebd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# step 4. Compute the loss, gradients, and update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
