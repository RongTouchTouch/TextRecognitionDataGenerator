{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter, IndexConverter\n",
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "from generate import gen_text_img\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "from models.densenet_ import DenseNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs targets ready for the network.\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        target_lengths = sample.target_lengths.to(device)\n",
    "        targets = sample.targets # Expected targets to have CPU Backend\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        images = sample.images\n",
    "        if isinstance(images, tuple):\n",
    "            targets = targets.to(device)\n",
    "            log_probs = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image).squeeze(1)\n",
    "                log_probs.append(log_prob)\n",
    "            input_lengths = torch.IntTensor([i.size(0) for i in log_probs]).to(device)\n",
    "            log_probs = pad_sequence(log_probs)\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            log_probs = pad_sequence(log_probs)\n",
    "            input_lengths = torch.full((images.size(0),), log_probs.size(0), dtype=torch.int32, device=device)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        if isinstance(images, tuple):\n",
    "            preds = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image)\n",
    "                preds.append(converter.best_path_decode(log_prob, strings=False))\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            print(pred)\n",
    "            print(target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# alphabet/alphabet_decode_5990.txt\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--max-epoch','100','--optimizer','rmsprop','--gpu-id','-1','--not-pretrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using model from scratch (random weights) 'densenet121'\n"
     ]
    }
   ],
   "source": [
    "global args, device\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "model = DenseNet(img_height=32, drop_rate=0.2, num_classes=len(args.alphabet) + 1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f36d05af320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36d88b12e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "\n",
    "num = 100\n",
    "dev_num = int(num/5)\n",
    "use_file = 1\n",
    "text_length = 10\n",
    "font_size = 0\n",
    "font_id = 1\n",
    "space_width = 1\n",
    "text_color = '#282828'\n",
    "thread_count = 8\n",
    "\n",
    "random_skew = False\n",
    "skew_angle = 0\n",
    "random_blur = False\n",
    "blur = 0\n",
    "\n",
    "distorsion = 0\n",
    "background = 1\n",
    "\n",
    "text_meta, text_img = gen_text_img(num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "\n",
    "index_converter = IndexConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "train_dataset = InMemoryDigitsDataset(mode='train',text=text_meta,img=text_img,total=num,\n",
    "                                      transform=transform, converter = index_converter)\n",
    "dev_dataset = InMemoryDigitsDataset(mode='dev', text=dev_meta, img=dev_img, total=dev_num,\n",
    "                                    transform=transform, converter = index_converter)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=collate_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "# for i in range(100):\n",
    "#     img, label = train_dataset.__getitem__(i)\n",
    "#     print(img.shape,label)\n",
    "plt.imshow(train_dataset.__getitem__(0)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train: [1][1/2]\tTime 7.165 (7.165)\tData 0.098 (0.098)\tLoss -2.8411 (-2.8411)\n",
      ">> Train: [1][2/2]\tTime 4.003 (5.584)\tData 0.001 (0.049)\tLoss -2.5131 (-2.6771)\n",
      "[1268]\n",
      "[1, 945, 561, 9, 1795, 75, 162, 29, 1505, 994]\n",
      "[1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268]\n",
      "[31, 230, 3, 760, 733, 266, 1, 93, 456, 61]\n",
      "[1268, 5038, 1268, 5038, 1268, 5038]\n",
      "[153, 554, 153, 365, 56, 1131, 34, 54, 161, 4]\n",
      "[1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268]\n",
      "[2, 34, 153, 504, 868, 528, 188, 168, 79, 161]\n",
      "[1268, 5038, 1268, 5038, 1268]\n",
      "[162, 142, 754, 143, 142, 754, 56, 530, 2649, 607]\n",
      "[5038, 1268, 5038, 1268, 5038]\n",
      "[27, 153, 895, 6, 45, 32, 165, 544, 3, 32]\n",
      "[5038, 1268, 5038, 1268, 5038, 1268, 5038]\n",
      "[456, 61, 912, 188, 168, 32, 1058, 5, 774, 1]\n",
      "[1268, 5038, 1268, 5038, 1268]\n",
      "[1676, 350, 1124, 561, 66, 719, 69, 3, 416, 259]\n",
      "[5038, 1268, 5038, 1268, 5038, 1268, 5038]\n",
      "[315, 234, 5, 28, 2746, 1042, 74, 40, 471, 3]\n",
      "[5038, 1268, 5038, 1268, 5038]\n",
      "[505, 183, 188, 168, 920, 1411, 4, 332, 115, 1795]\n",
      "[1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268]\n",
      "[642, 1548, 1, 34, 721, 55, 889, 245, 1, 40]\n",
      "[5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268]\n",
      "[1051, 1, 188, 478, 2163, 1621, 45, 1554, 1554, 3258]\n",
      "[5038, 1268, 5038]\n",
      "[3258, 3, 1760, 1405, 1, 1725, 92, 34, 245, 525]\n",
      "[5038, 1268, 5038, 1268, 5038, 1268, 5038, 1268, 5038]\n",
      "[19, 3, 1886, 1058, 45, 173, 4, 188, 168, 1484]\n",
      "[1268, 5038, 1268, 5038, 1268, 5038, 1268]\n",
      "[925, 3, 760, 733, 266, 25, 2354, 1365, 1159, 445]\n",
      "[5038, 1268, 5038, 1268, 5038]\n",
      "[1, 34, 1012, 889, 1, 188, 168, 2354, 2266, 686]\n",
      "[5038, 1268, 5038, 1268, 5038]\n",
      "[990, 850, 18, 5, 1170, 721, 134, 286, 3744, 1586]\n",
      "[1268]\n",
      "[18, 2, 60, 149, 188, 168, 296, 1058, 1058, 3]\n",
      "[1268, 5038, 1268, 5038]\n",
      "[134, 105, 6, 1442, 452, 3, 4, 34, 3, 126]\n",
      "[5038]\n",
      "[32, 471, 1723, 165, 1077, 2882, 185, 1136, 435, 3]\n",
      ">> Val: [1][1/1]\tTime 0.377 (0.377)\tAccu 0.000\n",
      ">> Train: [2][1/2]\tTime 6.922 (6.922)\tData 0.077 (0.077)\tLoss -2.2384 (-2.2384)\n",
      ">> Train: [2][2/2]\tTime 2.998 (4.960)\tData 0.002 (0.039)\tLoss -2.0199 (-2.1292)\n",
      "[5203]\n",
      "[1, 945, 561, 9, 1795, 75, 162, 29, 1505, 994]\n",
      "[5203]\n",
      "[31, 230, 3, 760, 733, 266, 1, 93, 456, 61]\n",
      "[5203]\n",
      "[153, 554, 153, 365, 56, 1131, 34, 54, 161, 4]\n",
      "[5203]\n",
      "[2, 34, 153, 504, 868, 528, 188, 168, 79, 161]\n",
      "[5203]\n",
      "[162, 142, 754, 143, 142, 754, 56, 530, 2649, 607]\n",
      "[5203]\n",
      "[27, 153, 895, 6, 45, 32, 165, 544, 3, 32]\n",
      "[5203]\n",
      "[456, 61, 912, 188, 168, 32, 1058, 5, 774, 1]\n",
      "[5203]\n",
      "[1676, 350, 1124, 561, 66, 719, 69, 3, 416, 259]\n",
      "[5203]\n",
      "[315, 234, 5, 28, 2746, 1042, 74, 40, 471, 3]\n",
      "[5203]\n",
      "[505, 183, 188, 168, 920, 1411, 4, 332, 115, 1795]\n",
      "[5203]\n",
      "[642, 1548, 1, 34, 721, 55, 889, 245, 1, 40]\n",
      "[5203]\n",
      "[1051, 1, 188, 478, 2163, 1621, 45, 1554, 1554, 3258]\n",
      "[5203]\n",
      "[3258, 3, 1760, 1405, 1, 1725, 92, 34, 245, 525]\n",
      "[5203]\n",
      "[19, 3, 1886, 1058, 45, 173, 4, 188, 168, 1484]\n",
      "[5203]\n",
      "[925, 3, 760, 733, 266, 25, 2354, 1365, 1159, 445]\n",
      "[5203]\n",
      "[1, 34, 1012, 889, 1, 188, 168, 2354, 2266, 686]\n",
      "[5203]\n",
      "[990, 850, 18, 5, 1170, 721, 134, 286, 3744, 1586]\n",
      "[5203]\n",
      "[18, 2, 60, 149, 188, 168, 296, 1058, 1058, 3]\n",
      "[5203]\n",
      "[134, 105, 6, 1442, 452, 3, 4, 34, 3, 126]\n",
      "[5203]\n",
      "[32, 471, 1723, 165, 1077, 2882, 185, 1136, 435, 3]\n",
      ">> Val: [2][1/1]\tTime 0.386 (0.386)\tAccu 0.000\n",
      ">> Train: [3][1/2]\tTime 6.851 (6.851)\tData 0.092 (0.092)\tLoss -1.9060 (-1.9060)\n",
      ">> Train: [3][2/2]\tTime 2.696 (4.774)\tData 0.001 (0.046)\tLoss -1.7710 (-1.8385)\n",
      "[5203]\n",
      "[1, 945, 561, 9, 1795, 75, 162, 29, 1505, 994]\n",
      "[5203]\n",
      "[31, 230, 3, 760, 733, 266, 1, 93, 456, 61]\n",
      "[5203]\n",
      "[153, 554, 153, 365, 56, 1131, 34, 54, 161, 4]\n",
      "[5203]\n",
      "[2, 34, 153, 504, 868, 528, 188, 168, 79, 161]\n",
      "[5203]\n",
      "[162, 142, 754, 143, 142, 754, 56, 530, 2649, 607]\n",
      "[5203]\n",
      "[27, 153, 895, 6, 45, 32, 165, 544, 3, 32]\n",
      "[5203]\n",
      "[456, 61, 912, 188, 168, 32, 1058, 5, 774, 1]\n",
      "[5203]\n",
      "[1676, 350, 1124, 561, 66, 719, 69, 3, 416, 259]\n",
      "[5203]\n",
      "[315, 234, 5, 28, 2746, 1042, 74, 40, 471, 3]\n",
      "[5203]\n",
      "[505, 183, 188, 168, 920, 1411, 4, 332, 115, 1795]\n",
      "[5203]\n",
      "[642, 1548, 1, 34, 721, 55, 889, 245, 1, 40]\n",
      "[5203]\n",
      "[1051, 1, 188, 478, 2163, 1621, 45, 1554, 1554, 3258]\n",
      "[5203]\n",
      "[3258, 3, 1760, 1405, 1, 1725, 92, 34, 245, 525]\n",
      "[5203]\n",
      "[19, 3, 1886, 1058, 45, 173, 4, 188, 168, 1484]\n",
      "[5203]\n",
      "[925, 3, 760, 733, 266, 25, 2354, 1365, 1159, 445]\n",
      "[5203]\n",
      "[1, 34, 1012, 889, 1, 188, 168, 2354, 2266, 686]\n",
      "[5203]\n",
      "[990, 850, 18, 5, 1170, 721, 134, 286, 3744, 1586]\n",
      "[5203]\n",
      "[18, 2, 60, 149, 188, 168, 296, 1058, 1058, 3]\n",
      "[5203]\n",
      "[134, 105, 6, 1442, 452, 3, 4, 34, 3, 126]\n",
      "[5203]\n",
      "[32, 471, 1723, 165, 1077, 2882, 185, 1136, 435, 3]\n",
      ">> Val: [3][1/1]\tTime 0.409 (0.409)\tAccu 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6a19327fbdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# train for one epoch on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-41a268b27268>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# do one step for multiple batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
