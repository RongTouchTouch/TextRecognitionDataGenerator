{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter, IndexConverter\n",
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "from generate import gen_text_img\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "from models.densenet_ import DenseNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs targets ready for the network.\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        target_lengths = sample.target_lengths.to(device)\n",
    "        targets = sample.targets # Expected targets to have CPU Backend\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        images = sample.images\n",
    "        if isinstance(images, tuple):\n",
    "            targets = targets.to(device)\n",
    "            log_probs = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image).squeeze(1)\n",
    "                log_probs.append(log_prob)\n",
    "            input_lengths = torch.IntTensor([i.size(0) for i in log_probs]).to(device)\n",
    "            log_probs = pad_sequence(log_probs)\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            #log_probs = pad_sequence(log_probs)\n",
    "            input_lengths = torch.full((images.size(0),), log_probs.size(0), dtype=torch.int32, device=device)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        if isinstance(images, tuple):\n",
    "            preds = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image)\n",
    "                preds.append(converter.best_path_decode(log_prob, strings=False))\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            print(pred)\n",
    "            print(target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# alphabet/alphabet_decode_5990.txt\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--max-epoch','100','--optimizer','rmsprop','--gpu-id','-1','--resume','densenet121_pretrained.pth.tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using pre-trained model 'densenet121'\n"
     ]
    }
   ],
   "source": [
    "global args, device\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "model_params = {}\n",
    "model_params['architecture'] = args.arch\n",
    "model_params['num_classes'] = len(args.alphabet) + 1\n",
    "model_params['mean'] = (0.5,)\n",
    "model_params['std'] = (0.5,)\n",
    "model_params['pretrained'] = args.pretrained\n",
    "model = init_network(model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = 'pretrained/densenet121_pretrained.pth'\n",
    "checkpoint = torch.load(model_path,map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "# model = DenseNet(img_height=32, drop_rate=0.2, num_classes=len(args.alphabet) + 1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "\n",
    "num = 1000\n",
    "dev_num = int(num/5)\n",
    "use_file = 1\n",
    "text_length = 10\n",
    "font_size = 0\n",
    "font_id = 1\n",
    "space_width = 1\n",
    "text_color = '#282828'\n",
    "thread_count = 8\n",
    "\n",
    "random_skew = False\n",
    "skew_angle = 0\n",
    "random_blur = False\n",
    "blur = 0\n",
    "\n",
    "distorsion = 0\n",
    "background = 1\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(100):\n",
    "#     img, label = train_dataset.__getitem__(i)\n",
    "#     print(img.shape,label)\n",
    "# plt.imshow(train_dataset.__getitem__(0)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138868\n",
      "156987\n",
      "43185\n",
      "60313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 295, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "RuntimeError: unable to write to file </torch_32657_3948723417>\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 295, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "RuntimeError: unable to write to file </torch_32658_2956650664>\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/jovyan/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 295, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_32656_1800311011>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/jovyan/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 295, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_32656_3527042512>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 32659) is killed by signal: Bus error. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-78a3f394ae57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# train for one epoch on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e3dce5081f6b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m#log_probs = pad_sequence(log_probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TextRecognitionDataGenerator/models/crnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# x -> features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# features -> pool -> flatten -> classifier -> softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TextRecognitionDataGenerator/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TextRecognitionDataGenerator/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *prev_features)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TextRecognitionDataGenerator/models/densenet.py\u001b[0m in \u001b[0;36mbn_function\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mconcated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcated_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbottleneck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 32659) is killed by signal: Bus error. "
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    text_meta, text_img = gen_text_img(num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "    dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "\n",
    "    index_converter = IndexConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "    train_dataset = InMemoryDigitsDataset(mode='train',text=text_meta,img=text_img,total=num,\n",
    "                                      transform=transform, converter = index_converter)\n",
    "    dev_dataset = InMemoryDigitsDataset(mode='dev', text=dev_meta, img=dev_img, total=dev_num,\n",
    "                                    transform=transform, converter = index_converter)\n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "    dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=collate_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3742d1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "param_not_modified_acc=[0.906,0.940,0.984,0.975,0.984,0.980,0.984]\n",
    "feature_set_random_acc=[0.953,0.950,0.969,0.960,0.980,0.985,0.975]\n",
    "# feature_set_zero_acc=[0.9,0.98,0.92,0.92,1,0.98,1]\n",
    "# feature_set_random_acc=[0.8,0.9,0.9,0.85,0.8,0.9,0.95]\n",
    "x = [1,2,3,4,5,6,7]#点的横坐标\n",
    "plt.plot(x,param_not_modified_acc,color = 'b',label=\"param-not-modified\")\n",
    "# plt.plot(x,feature_set_zero_acc,color = 'r',label=\"feature_set_zero\")\n",
    "plt.plot(x,feature_set_random_acc,color = 'g',label=\"feature_set_random\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
