{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter, IndexConverter\n",
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "from generate import gen_text_img\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "from models.densenet_ import DenseNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs targets ready for the network.\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        target_lengths = sample.target_lengths.to(device)\n",
    "        targets = sample.targets # Expected targets to have CPU Backend\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        images = sample.images\n",
    "        if isinstance(images, tuple):\n",
    "            targets = targets.to(device)\n",
    "            log_probs = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image).squeeze(1)\n",
    "                log_probs.append(log_prob)\n",
    "            input_lengths = torch.IntTensor([i.size(0) for i in log_probs]).to(device)\n",
    "            log_probs = pad_sequence(log_probs)\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            #log_probs = pad_sequence(log_probs)\n",
    "            input_lengths = torch.full((images.size(0),), log_probs.size(0), dtype=torch.int32, device=device)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        if isinstance(images, tuple):\n",
    "            preds = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image)\n",
    "                preds.append(converter.best_path_decode(log_prob, strings=False))\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "#             print(pred)\n",
    "#             print(target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# alphabet/alphabet_decode_5990.txt\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--max-epoch','30','--optimizer','rmsprop','--gpu-id','-1','--resume','densenet121_pretrained.pth.tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using pre-trained model 'densenet121'\n"
     ]
    }
   ],
   "source": [
    "global args, device\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "model_params = {}\n",
    "model_params['architecture'] = args.arch\n",
    "model_params['num_classes'] = len(args.alphabet) + 1\n",
    "model_params['mean'] = (0.5,)\n",
    "model_params['std'] = (0.5,)\n",
    "model_params['pretrained'] = args.pretrained\n",
    "model = init_network(model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = 'pretrained/densenet121_pretrained.pth'\n",
    "checkpoint = torch.load(model_path,map_location = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-0.0055, -0.2964, -0.2471,  ..., -0.1523, -0.1538, -0.1528],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[-0.3986, -0.5298, -0.5443,  ..., -0.2359, -0.6787, -0.5275],\n",
       "         [-0.1850, -0.2860, -1.0046,  ..., -0.9901, -0.4477, -0.8112],\n",
       "         [-0.6358, -0.5752, -0.6929,  ..., -0.4457, -0.7367, -0.5674],\n",
       "         ...,\n",
       "         [-0.5230, -0.5352, -0.5225,  ..., -0.5775, -0.5941, -0.6068],\n",
       "         [-0.5254, -0.5340, -0.5250,  ..., -0.5906, -0.5832, -0.6025],\n",
       "         [-0.5192, -0.5336, -0.5224,  ..., -0.5762, -0.5925, -0.6057]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.5880, 0.4279, 0.8182, 0.8355, 0.6955, 1.3528, 0.4871, 0.8687, 0.7586,\n",
       "         0.9785, 0.8345, 1.3331, 0.5226, 0.6628, 0.8947, 0.5422, 0.5403, 0.6396,\n",
       "         0.8607, 0.8309, 0.9317, 0.8057, 0.9259, 1.2925, 0.3643, 1.0547, 1.0428,\n",
       "         0.7793, 0.7593, 0.7541, 0.6469, 0.6868, 0.8050, 0.6996, 1.1012, 0.4494,\n",
       "         0.9548, 0.9394, 1.0519, 0.7682, 0.8002, 0.6295, 0.3747, 0.7116, 0.7297,\n",
       "         0.4756, 0.6010, 0.5929, 0.9139, 0.5315, 0.8832, 0.7405, 0.8988, 1.0635,\n",
       "         1.0162, 0.8834, 1.0052, 0.8371, 0.5124, 0.8270, 0.5888, 0.5964, 0.5175,\n",
       "         1.0901, 0.5429, 0.6422, 0.6394, 1.1622, 0.9729, 0.8541, 1.0252, 0.4940,\n",
       "         0.8914, 0.5884, 0.7362, 0.4155, 0.9104, 0.7692, 0.7992, 0.5298, 1.0859,\n",
       "         0.7400, 0.7690, 0.5113, 1.0398, 0.8837, 0.6285, 0.5775, 0.8495, 0.7441,\n",
       "         0.8269, 1.0655, 0.9343, 0.8109, 0.7957, 0.6221, 0.6715, 0.4688, 0.6758,\n",
       "         0.8098, 0.8817, 0.8690, 0.7741, 0.8859, 0.8111, 0.8529, 0.6297, 0.8045,\n",
       "         0.4945, 0.3038, 0.6207, 0.8311, 0.6150, 0.9273, 0.5853, 0.8498, 0.8019,\n",
       "         0.5131, 0.8205, 0.9773, 0.9785, 0.9127, 0.6171, 0.9754, 0.9100, 0.7441,\n",
       "         0.4505, 0.9337, 0.5871, 0.8461, 0.9280, 0.8880, 0.1996, 0.4217, 0.7981,\n",
       "         0.9792, 1.1429, 0.8025, 0.6234, 0.9094, 0.9504, 0.7852, 0.4549, 0.8909,\n",
       "         0.8520, 0.8284, 0.9478, 0.7526, 0.7295, 0.4554, 0.8526, 0.6006, 1.1627,\n",
       "         0.7616, 0.8817, 0.5464, 0.9490, 0.9132, 0.8167, 0.4938, 0.5298, 0.7364,\n",
       "         0.9255, 0.5561, 0.7717, 0.7724, 1.0287, 0.9392, 0.7308, 0.7982, 0.6499,\n",
       "         0.3504, 0.9871, 1.0721, 0.6033, 0.4369, 1.1382, 0.7208, 0.8285, 0.9250,\n",
       "         0.8493, 0.7268, 0.5044, 0.9729, 0.7167, 0.6518, 0.6422, 0.6996, 1.1732,\n",
       "         1.0883, 0.9011, 0.6667, 0.6797, 0.7577, 0.8209, 1.0382, 0.6596, 0.2961,\n",
       "         1.0771, 0.6441, 0.6779, 0.7689, 1.2869, 0.7234, 0.8896, 0.7116, 1.4777,\n",
       "         0.6686, 0.6191, 0.5455, 0.8355, 0.9858, 0.6347, 0.8792, 0.3931, 0.5764,\n",
       "         1.0921, 0.5035, 0.9358, 0.4322, 1.0305, 0.7241, 0.3502, 0.6961, 0.8553,\n",
       "         1.4051, 0.4507, 0.4049, 0.9506, 0.5934, 0.7620, 0.8516, 0.3904, 0.7483,\n",
       "         0.7315, 0.4101, 0.9266, 0.8258, 0.6109, 0.6940, 0.8801, 0.6528, 0.5309,\n",
       "         0.6172, 1.0200, 0.5919, 0.6043, 0.8196, 0.3260, 0.8618, 1.0170, 1.1233,\n",
       "         0.8321, 0.7931, 0.8468, 0.6786, 0.8538, 0.6345, 0.3841, 0.7065, 0.8203,\n",
       "         0.7627, 0.3638, 0.5056, 0.8349, 0.9038, 0.2734, 0.8159, 0.4037, 0.9487,\n",
       "         0.2591, 0.7776, 0.4216, 0.9149, 0.7969, 0.7267, 0.7028, 0.9076, 0.6797,\n",
       "         0.4010, 0.5572, 0.6653, 0.1366, 0.2301, 0.8715, 0.6761, 0.1514, 0.3914,\n",
       "         1.1467, 0.7475, 0.9155, 0.2816, 0.3306, 1.0327, 0.6662, 0.5457, 0.5411,\n",
       "         0.6688, 0.9074, 0.8297, 0.4896, 0.8825, 0.2020, 0.6775, 0.3956, 0.6793,\n",
       "         0.6340, 0.3847, 0.7158, 0.7029, 0.4659, 0.4192, 0.8328, 0.4847, 0.8277,\n",
       "         0.9971, 0.6170, 0.6339, 0.7456, 0.6347, 0.4337, 0.4186, 0.3553, 1.0160,\n",
       "         0.9909, 0.3292, 0.9541, 0.4968, 0.8327, 0.9935, 0.3750, 0.4397, 0.1755,\n",
       "         0.7857, 0.6591, 0.4889, 0.5415, 0.7057, 0.6144, 0.6682, 0.6134, 0.5041,\n",
       "         1.0242, 0.7829, 0.8635, 0.4005, 0.4117, 0.2559, 0.2132, 0.6216, 0.8235,\n",
       "         0.3277, 0.3621, 0.8908, 0.7649, 0.3663, 0.8497, 0.1959, 0.6333, 0.9517,\n",
       "         1.0043, 0.6862, 0.1122, 0.6209, 0.6009, 0.9729, 0.3861, 0.8794, 1.0332,\n",
       "         0.7927, 0.9526, 0.6341, 0.6089, 0.8964, 0.7273, 0.7209, 0.0395, 0.4322,\n",
       "         0.5116, 0.7821, 0.7014, 0.9520, 0.8079, 1.0540], requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)\n",
    "list(reversed([p for p in model.parameters()]))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1672, -0.1077,  0.0997,  ..., -0.0012,  0.0975, -0.1065])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parameters = [p for p in model.parameters() if p.requires_grad==True]\n",
    "total_n_paras = len(all_parameters)\n",
    "\n",
    "all_parameters[-1].data.normal_(0., 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5990])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parameters[-1].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1672, -0.1077,  0.0997,  ..., -0.0012,  0.0975, -0.1065],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4534, 2.3537, 2.6194, 1.7306, 1.5976, 2.9811, 2.3410, 2.4930, 3.0588,\n",
      "        2.6595, 3.0670, 2.7643, 1.6455, 1.8844, 2.6390, 2.3321, 2.5897, 1.8171,\n",
      "        2.2716, 1.9729, 1.8891, 2.6920, 2.3127, 2.6115, 1.5984, 2.1330, 2.2537,\n",
      "        2.0043, 2.3838, 2.2825, 2.7591, 2.7217, 2.4848, 2.4448, 2.1355, 2.3835,\n",
      "        2.2789, 1.8638, 2.1268, 1.7026, 2.4160, 1.9143, 2.0464, 2.5165, 2.4811,\n",
      "        2.4863, 2.4346, 1.7786, 1.8920, 2.7174, 2.3715, 2.3956, 1.7125, 2.2667,\n",
      "        2.5423, 3.3810, 2.4385, 2.5949, 2.8287, 2.0383, 2.8236, 2.1133, 1.8154,\n",
      "        2.5218, 2.2491, 1.8703, 2.3990, 2.2270, 2.8488, 2.5339, 2.5493, 2.2292,\n",
      "        1.8395, 2.8651, 2.2474, 2.2236, 2.4867, 2.3955, 2.1859, 2.4878, 2.8370,\n",
      "        2.7603, 2.7653, 2.7237, 2.6169, 2.4474, 2.6125, 1.8670, 2.0150, 2.4808,\n",
      "        2.8697, 2.7390, 3.0999, 2.8175, 2.5124, 2.5457, 1.8832, 2.5557, 2.3579,\n",
      "        1.9962, 2.4011, 2.5110, 2.7210, 2.9091, 2.6077, 2.6369, 1.9089, 3.2170,\n",
      "        2.3662, 2.6405, 2.4488, 2.2827, 1.8860, 2.3263, 2.3647, 2.9744, 2.4161,\n",
      "        2.7624, 2.2706, 2.4796, 2.3210, 2.0536, 2.0824, 2.6498, 2.0113, 2.4882,\n",
      "        2.1869, 2.8935, 2.5611, 2.0961, 2.4981, 2.4135, 2.0716, 3.0093, 2.2655,\n",
      "        2.0217, 2.4310, 2.2411, 1.6068, 2.0106, 2.6068, 3.1264, 2.6891, 3.0552,\n",
      "        2.6095, 2.5449, 1.6788, 2.2895, 2.1829, 2.2413, 1.8858, 2.4520, 2.3075,\n",
      "        2.3774, 2.4879, 2.3594, 1.9350, 2.3561, 2.8357, 2.6894, 2.0821, 2.1493,\n",
      "        2.3118, 2.5470, 2.0932, 2.0236, 2.8098, 2.6721, 2.3400, 2.4731, 2.9590,\n",
      "        2.3614, 2.5997, 2.8489, 2.4654, 2.4939, 2.4616, 2.3040, 2.1106, 1.5615,\n",
      "        1.2293, 2.5037, 2.1952, 2.5392, 2.0549, 2.3028, 2.9663, 2.7932, 1.9862,\n",
      "        2.5656, 2.0920, 1.9531, 1.9482, 2.8323, 2.5723, 2.1248, 2.1946, 2.5088,\n",
      "        2.6904, 2.3322, 1.8275, 1.8449, 2.5175, 2.6550, 2.8935, 2.5124, 2.4557,\n",
      "        2.7307, 1.7321, 1.9726, 2.5892, 2.4885, 2.4516, 2.6364, 2.2668, 2.5606,\n",
      "        1.4652, 2.7305, 2.4906, 2.2970, 2.6831, 2.9252, 2.3498, 2.2158, 2.4496,\n",
      "        2.3150, 2.1176, 1.4810, 1.9350, 3.0638, 2.1135, 2.3123, 2.6287, 2.6803,\n",
      "        2.8818, 2.8678, 2.9000, 2.1882, 2.9448, 2.0034, 2.4413, 2.2127, 1.7598,\n",
      "        2.4420, 2.6838, 2.2779, 2.1825, 2.8023, 2.6380, 2.4714, 2.8469, 2.5378,\n",
      "        2.0265, 2.6597, 2.3401, 2.1975, 2.3317, 2.0255, 2.5272, 1.9303, 2.5132,\n",
      "        2.0848, 3.0588, 2.5824, 1.7869, 2.6604, 2.4209, 2.0455, 2.4010, 2.2891,\n",
      "        2.5883, 2.3026, 2.4489, 2.5058, 2.3992, 2.8243, 2.4693, 2.5059, 2.4128,\n",
      "        2.6603, 1.9069, 2.9814, 2.2444, 2.3631, 1.8936, 2.9255, 1.9739, 2.2209,\n",
      "        2.3297, 1.5386, 2.1166, 2.4216, 2.8198, 2.8559, 2.7920, 2.7469, 2.1001,\n",
      "        3.2356, 2.9073, 2.1131, 2.4931, 2.0777, 2.0741, 2.3387, 2.3225, 2.9291,\n",
      "        2.4911, 2.4471, 2.2084, 2.4416, 2.2369, 2.3633, 2.3203, 2.0946, 1.8415,\n",
      "        2.3411, 2.2482, 2.1685, 1.5616, 2.5721, 2.1250, 2.1959, 1.9561, 2.1610,\n",
      "        2.5578, 1.6230, 2.7292, 2.5062, 2.0986, 2.0060, 1.5494, 2.1966, 2.1102,\n",
      "        2.2904, 2.0841, 2.7677, 2.8336, 2.4332, 1.7721, 2.8334, 2.2873, 2.7560,\n",
      "        1.7918, 2.2821, 2.2015, 2.3921, 2.3861, 2.2520, 2.6484, 2.9997, 2.7722,\n",
      "        2.4683, 2.2458, 2.5793, 2.6453, 2.5223, 2.6248, 2.1727, 2.4488, 2.2964,\n",
      "        1.7425, 2.2913, 2.0621, 2.4832, 3.0930, 2.6865, 2.0769, 2.7212, 2.6037,\n",
      "        2.2047, 2.4047, 2.0991, 2.1776, 2.7401, 2.1255, 1.7122, 2.5808, 1.5872,\n",
      "        2.6846, 2.1498, 1.5271, 2.5931, 2.0557, 2.2430])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for i, j in model.named_parameters():\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "idx = random.sample(range(384),384)\n",
    "random_param = torch.rand(384)\n",
    "zero_param = torch.Tensor([0.0]*384)\n",
    "\n",
    "#checkpoint[\"classifier.weight\"] = torch.rand(5990,384)\n",
    "#checkpoint[\"features.8.weight\"] = zero_param\n",
    "#checkpoint[\"features.8.weight\"] = random_param\n",
    "checkpoint[\"features.8.weight\"] = checkpoint[\"features.8.weight\"][idx]\n",
    "#print(checkpoint[\"classifier.weight\"])\n",
    "print(checkpoint[\"features.8.weight\"])\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "torch.save(checkpoint, \"pretrained/weights.pth\")\n",
    "\n",
    "# model = DenseNet(img_height=32, drop_rate=0.2, num_classes=len(args.alphabet) + 1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "\n",
    "num = 200\n",
    "dev_num = num\n",
    "use_file = 1\n",
    "text_length = 10\n",
    "font_size = 0\n",
    "font_id = 1\n",
    "space_width = 1\n",
    "text_color = '#282828'\n",
    "thread_count = 8\n",
    "\n",
    "random_skew = False\n",
    "skew_angle = 0\n",
    "random_blur = False\n",
    "blur = 0\n",
    "\n",
    "distorsion = 0\n",
    "background = 1\n",
    "\n",
    "# for i in range(100):\n",
    "#     img, label = train_dataset.__getitem__(i)\n",
    "#     print(img.shape,label)\n",
    "# plt.imshow(train_dataset.__getitem__(0)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40283\n",
      "28911\n",
      "49979\n",
      "35731\n",
      ">> Train: [1][1/4]\tTime 12.969 (12.969)\tData 0.103 (0.103)\tLoss 0.5945 (0.5945)\n",
      ">> Train: [1][4/4]\tTime 1.511 (9.413)\tData 0.000 (0.028)\tLoss 0.1049 (0.2413)\n",
      ">> Val: [1][1/4]\tTime 3.443 (3.443)\tAccu 0.828\n",
      ">> Val: [1][4/4]\tTime 0.277 (2.175)\tAccu 0.805\n",
      ">>>> save best model at epoch: 1\n",
      "40725\n",
      "24285\n",
      "52957\n",
      "15456\n",
      ">> Train: [2][1/4]\tTime 12.175 (12.175)\tData 0.203 (0.203)\tLoss 0.0243 (0.0243)\n",
      ">> Train: [2][4/4]\tTime 1.620 (9.599)\tData 0.000 (0.054)\tLoss 0.0056 (0.0206)\n",
      ">> Val: [2][1/4]\tTime 3.085 (3.085)\tAccu 0.891\n",
      ">> Val: [2][4/4]\tTime 0.298 (2.017)\tAccu 0.850\n",
      ">>>> save best model at epoch: 2\n",
      "32351\n",
      "65092\n",
      "51585\n",
      "8818\n",
      ">> Train: [3][1/4]\tTime 13.373 (13.373)\tData 0.226 (0.226)\tLoss 0.0514 (0.0514)\n",
      ">> Train: [3][4/4]\tTime 1.551 (10.366)\tData 0.000 (0.059)\tLoss 0.0020 (0.0297)\n",
      ">> Val: [3][1/4]\tTime 3.294 (3.294)\tAccu 0.969\n",
      ">> Val: [3][4/4]\tTime 0.304 (2.203)\tAccu 0.910\n",
      ">>>> save best model at epoch: 3\n",
      "3456\n",
      "1566\n",
      "68616\n",
      "65771\n",
      ">> Train: [4][1/4]\tTime 13.090 (13.090)\tData 0.189 (0.189)\tLoss 0.0262 (0.0262)\n",
      ">> Train: [4][4/4]\tTime 1.522 (10.280)\tData 0.000 (0.050)\tLoss 0.0041 (0.0189)\n",
      ">> Val: [4][1/4]\tTime 3.484 (3.484)\tAccu 0.953\n",
      ">> Val: [4][4/4]\tTime 0.291 (2.227)\tAccu 0.910\n",
      ">>>> save best model at epoch: 4\n",
      "59261\n",
      "20486\n",
      "32036\n",
      "19251\n",
      ">> Train: [5][1/4]\tTime 13.342 (13.342)\tData 0.226 (0.226)\tLoss 0.0317 (0.0317)\n",
      ">> Train: [5][4/4]\tTime 1.672 (10.465)\tData 0.000 (0.057)\tLoss 0.0042 (0.0197)\n",
      ">> Val: [5][1/4]\tTime 2.823 (2.823)\tAccu 0.984\n",
      ">> Val: [5][4/4]\tTime 0.292 (1.994)\tAccu 0.965\n",
      ">>>> save best model at epoch: 5\n",
      "30524\n",
      "34026\n",
      "33603\n",
      "67282\n",
      ">> Train: [6][1/4]\tTime 13.686 (13.686)\tData 0.197 (0.197)\tLoss 0.0127 (0.0127)\n",
      ">> Train: [6][4/4]\tTime 1.737 (10.621)\tData 0.000 (0.052)\tLoss 0.0067 (0.0114)\n",
      ">> Val: [6][1/4]\tTime 3.167 (3.167)\tAccu 1.000\n",
      ">> Val: [6][4/4]\tTime 0.372 (2.115)\tAccu 0.960\n",
      "40393\n",
      "57288\n",
      "23882\n",
      "34612\n",
      ">> Train: [7][1/4]\tTime 13.500 (13.500)\tData 0.213 (0.213)\tLoss 0.0230 (0.0230)\n",
      ">> Train: [7][4/4]\tTime 1.446 (10.355)\tData 0.001 (0.056)\tLoss 0.0485 (0.0256)\n",
      ">> Val: [7][1/4]\tTime 3.522 (3.522)\tAccu 1.000\n",
      ">> Val: [7][4/4]\tTime 0.353 (2.208)\tAccu 0.995\n",
      ">>>> save best model at epoch: 7\n",
      "64854\n",
      "12649\n",
      "30554\n",
      "24873\n",
      ">> Train: [8][1/4]\tTime 13.499 (13.499)\tData 0.191 (0.191)\tLoss 0.0091 (0.0091)\n",
      ">> Train: [8][4/4]\tTime 1.454 (10.308)\tData 0.000 (0.050)\tLoss 0.0153 (0.0258)\n",
      ">> Val: [8][1/4]\tTime 3.181 (3.181)\tAccu 1.000\n",
      ">> Val: [8][4/4]\tTime 0.350 (2.048)\tAccu 0.990\n",
      "5538\n",
      "27499\n",
      "35921\n",
      "47372\n",
      ">> Train: [9][1/4]\tTime 15.036 (15.036)\tData 0.225 (0.225)\tLoss 0.0335 (0.0335)\n",
      ">> Train: [9][4/4]\tTime 1.507 (10.970)\tData 0.000 (0.057)\tLoss 0.0148 (0.0233)\n",
      ">> Val: [9][1/4]\tTime 3.222 (3.222)\tAccu 0.922\n",
      ">> Val: [9][4/4]\tTime 0.293 (1.978)\tAccu 0.945\n",
      "64854\n",
      "30881\n",
      "46022\n",
      "63844\n",
      ">> Train: [10][1/4]\tTime 14.970 (14.970)\tData 0.214 (0.214)\tLoss 0.0044 (0.0044)\n",
      ">> Train: [10][4/4]\tTime 1.614 (11.146)\tData 0.000 (0.055)\tLoss 0.0282 (0.0224)\n",
      ">> Val: [10][1/4]\tTime 3.085 (3.085)\tAccu 1.000\n",
      ">> Val: [10][4/4]\tTime 0.280 (2.080)\tAccu 0.980\n",
      "30596\n",
      "55616\n",
      "27532\n",
      "54176\n",
      ">> Train: [11][1/4]\tTime 15.194 (15.194)\tData 0.242 (0.242)\tLoss 0.0102 (0.0102)\n",
      ">> Train: [11][4/4]\tTime 1.570 (11.105)\tData 0.000 (0.063)\tLoss 0.0088 (0.0109)\n",
      ">> Val: [11][1/4]\tTime 3.352 (3.352)\tAccu 1.000\n",
      ">> Val: [11][4/4]\tTime 0.275 (2.020)\tAccu 1.000\n",
      ">>>> save best model at epoch: 11\n",
      "31140\n",
      "64916\n",
      "38503\n",
      "21725\n",
      ">> Train: [12][1/4]\tTime 15.284 (15.284)\tData 0.230 (0.230)\tLoss 0.0152 (0.0152)\n",
      ">> Train: [12][4/4]\tTime 1.789 (11.193)\tData 0.000 (0.058)\tLoss 0.1196 (0.0443)\n",
      ">> Val: [12][1/4]\tTime 3.366 (3.366)\tAccu 0.938\n",
      ">> Val: [12][4/4]\tTime 0.345 (2.230)\tAccu 0.975\n",
      "65987\n",
      "248\n",
      "33603\n",
      "5024\n",
      ">> Train: [13][1/4]\tTime 15.797 (15.797)\tData 0.254 (0.254)\tLoss 0.0255 (0.0255)\n",
      ">> Train: [13][4/4]\tTime 1.750 (11.154)\tData 0.000 (0.067)\tLoss 0.0035 (0.0198)\n",
      ">> Val: [13][1/4]\tTime 3.057 (3.057)\tAccu 0.969\n",
      ">> Val: [13][4/4]\tTime 0.288 (1.936)\tAccu 0.945\n",
      "69973\n",
      "66992\n",
      "5387\n",
      "42577\n",
      ">> Train: [14][1/4]\tTime 15.668 (15.668)\tData 0.254 (0.254)\tLoss 0.0214 (0.0214)\n",
      ">> Train: [14][4/4]\tTime 1.739 (11.229)\tData 0.000 (0.065)\tLoss 0.0214 (0.0271)\n",
      ">> Val: [14][1/4]\tTime 3.533 (3.533)\tAccu 0.984\n",
      ">> Val: [14][4/4]\tTime 0.337 (2.120)\tAccu 0.985\n",
      "3858\n",
      "20326\n",
      "39985\n",
      "44828\n",
      ">> Train: [15][1/4]\tTime 15.421 (15.421)\tData 0.246 (0.246)\tLoss 0.0436 (0.0436)\n",
      ">> Train: [15][4/4]\tTime 1.712 (10.897)\tData 0.000 (0.064)\tLoss 0.0221 (0.0227)\n",
      ">> Val: [15][1/4]\tTime 3.273 (3.273)\tAccu 0.984\n",
      ">> Val: [15][4/4]\tTime 0.380 (2.259)\tAccu 0.985\n",
      "7089\n",
      "34026\n",
      "57325\n",
      "48497\n",
      ">> Train: [16][1/4]\tTime 15.096 (15.096)\tData 0.247 (0.247)\tLoss 0.0284 (0.0284)\n",
      ">> Train: [16][4/4]\tTime 1.794 (11.011)\tData 0.000 (0.063)\tLoss 0.0256 (0.0338)\n",
      ">> Val: [16][1/4]\tTime 3.138 (3.138)\tAccu 0.969\n",
      ">> Val: [16][4/4]\tTime 0.275 (1.906)\tAccu 0.970\n",
      "6415\n",
      "47022\n",
      "37987\n",
      "1566\n",
      ">> Train: [17][1/4]\tTime 15.774 (15.774)\tData 0.272 (0.272)\tLoss 0.0458 (0.0458)\n",
      ">> Train: [17][4/4]\tTime 1.747 (11.194)\tData 0.001 (0.068)\tLoss 0.0288 (0.0320)\n",
      ">> Val: [17][1/4]\tTime 3.385 (3.385)\tAccu 0.938\n",
      ">> Val: [17][4/4]\tTime 0.374 (2.163)\tAccu 0.960\n",
      "4904\n",
      "67282\n",
      "38369\n",
      "47372\n",
      ">> Train: [18][1/4]\tTime 15.854 (15.854)\tData 0.265 (0.265)\tLoss 0.0183 (0.0183)\n",
      ">> Train: [18][4/4]\tTime 1.699 (11.221)\tData 0.000 (0.067)\tLoss 0.0299 (0.0189)\n",
      ">> Val: [18][1/4]\tTime 3.416 (3.416)\tAccu 0.953\n",
      ">> Val: [18][4/4]\tTime 0.294 (2.192)\tAccu 0.970\n",
      "12413\n",
      "16497\n",
      "35703\n",
      "840\n",
      ">> Train: [19][1/4]\tTime 15.799 (15.799)\tData 0.251 (0.251)\tLoss 0.0636 (0.0636)\n",
      ">> Train: [19][4/4]\tTime 1.746 (11.299)\tData 0.000 (0.065)\tLoss 0.0098 (0.0676)\n",
      ">> Val: [19][1/4]\tTime 3.516 (3.516)\tAccu 0.875\n",
      ">> Val: [19][4/4]\tTime 0.335 (2.195)\tAccu 0.935\n",
      "57325\n",
      "1418\n",
      "23161\n",
      "44828\n",
      ">> Train: [20][1/4]\tTime 15.928 (15.928)\tData 0.248 (0.248)\tLoss 0.0188 (0.0188)\n",
      ">> Train: [20][4/4]\tTime 1.758 (11.270)\tData 0.005 (0.064)\tLoss 0.0125 (0.0281)\n",
      ">> Val: [20][1/4]\tTime 3.440 (3.440)\tAccu 0.969\n",
      ">> Val: [20][4/4]\tTime 0.275 (2.302)\tAccu 0.990\n",
      "51585\n",
      "4246\n",
      "36915\n",
      "55616\n",
      ">> Train: [21][1/4]\tTime 15.513 (15.513)\tData 0.263 (0.263)\tLoss 0.0479 (0.0479)\n",
      ">> Train: [21][4/4]\tTime 1.665 (11.304)\tData 0.000 (0.068)\tLoss 0.0007 (0.0174)\n",
      ">> Val: [21][1/4]\tTime 3.876 (3.876)\tAccu 0.922\n",
      ">> Val: [21][4/4]\tTime 0.284 (2.379)\tAccu 0.960\n",
      "73588\n",
      "21079\n",
      "5513\n",
      "67137\n",
      ">> Train: [22][1/4]\tTime 15.514 (15.514)\tData 0.271 (0.271)\tLoss 0.0083 (0.0083)\n",
      ">> Train: [22][4/4]\tTime 1.674 (11.147)\tData 0.000 (0.069)\tLoss 0.0015 (0.0062)\n",
      ">> Val: [22][1/4]\tTime 3.146 (3.146)\tAccu 0.984\n",
      ">> Val: [22][4/4]\tTime 0.278 (2.069)\tAccu 0.975\n",
      "33870\n",
      "38204\n",
      "1150\n",
      "1022\n",
      ">> Train: [23][1/4]\tTime 15.384 (15.384)\tData 0.261 (0.261)\tLoss 0.0413 (0.0413)\n",
      ">> Train: [23][4/4]\tTime 1.556 (11.235)\tData 0.000 (0.067)\tLoss 0.0360 (0.0387)\n",
      ">> Val: [23][1/4]\tTime 3.540 (3.540)\tAccu 0.953\n",
      ">> Val: [23][4/4]\tTime 0.349 (2.200)\tAccu 0.970\n",
      "61011\n",
      "14851\n",
      "63583\n",
      "22796\n",
      ">> Train: [24][1/4]\tTime 15.335 (15.335)\tData 0.260 (0.260)\tLoss 0.0641 (0.0641)\n",
      ">> Train: [24][4/4]\tTime 1.821 (11.243)\tData 0.000 (0.068)\tLoss 0.0022 (0.0272)\n",
      ">> Val: [24][1/4]\tTime 3.543 (3.543)\tAccu 0.984\n",
      ">> Val: [24][4/4]\tTime 0.282 (2.157)\tAccu 0.980\n",
      "37584\n",
      "799\n",
      "4108\n",
      "11913\n",
      ">> Train: [25][1/4]\tTime 16.101 (16.101)\tData 0.264 (0.264)\tLoss 0.0087 (0.0087)\n",
      ">> Train: [25][4/4]\tTime 1.744 (11.420)\tData 0.000 (0.069)\tLoss 0.0888 (0.0397)\n",
      ">> Val: [25][1/4]\tTime 3.537 (3.537)\tAccu 0.984\n",
      ">> Val: [25][4/4]\tTime 0.300 (2.325)\tAccu 0.990\n",
      "28258\n",
      "1566\n",
      "37397\n",
      "67914\n",
      ">> Train: [26][1/4]\tTime 15.667 (15.667)\tData 0.270 (0.270)\tLoss 0.0136 (0.0136)\n",
      ">> Train: [26][4/4]\tTime 1.736 (11.236)\tData 0.000 (0.069)\tLoss 0.0026 (0.0079)\n",
      ">> Val: [26][1/4]\tTime 3.636 (3.636)\tAccu 0.938\n",
      ">> Val: [26][4/4]\tTime 0.349 (2.342)\tAccu 0.970\n",
      "39985\n",
      "9703\n",
      "46042\n",
      "7411\n",
      ">> Train: [27][1/4]\tTime 15.575 (15.575)\tData 0.255 (0.255)\tLoss 0.0300 (0.0300)\n",
      ">> Train: [27][4/4]\tTime 1.769 (11.463)\tData 0.000 (0.067)\tLoss 0.0447 (0.0280)\n",
      ">> Val: [27][1/4]\tTime 3.288 (3.288)\tAccu 1.000\n",
      ">> Val: [27][4/4]\tTime 0.291 (2.066)\tAccu 0.975\n",
      "810\n",
      "67914\n",
      "26114\n",
      "56539\n",
      ">> Train: [28][1/4]\tTime 15.668 (15.668)\tData 0.275 (0.275)\tLoss 0.0219 (0.0219)\n",
      ">> Train: [28][4/4]\tTime 1.802 (11.282)\tData 0.000 (0.072)\tLoss 0.0049 (0.0348)\n",
      ">> Val: [28][1/4]\tTime 3.746 (3.746)\tAccu 1.000\n",
      ">> Val: [28][4/4]\tTime 0.287 (2.329)\tAccu 1.000\n",
      ">>>> save best model at epoch: 28\n",
      "34593\n",
      "65771\n",
      "25205\n",
      "799\n",
      ">> Train: [29][1/4]\tTime 15.723 (15.723)\tData 0.270 (0.270)\tLoss 0.0350 (0.0350)\n",
      ">> Train: [29][4/4]\tTime 1.755 (11.474)\tData 0.000 (0.069)\tLoss 0.0442 (0.0388)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Val: [29][1/4]\tTime 3.596 (3.596)\tAccu 1.000\n",
      ">> Val: [29][4/4]\tTime 0.345 (2.255)\tAccu 1.000\n",
      ">>>> save best model at epoch: 29\n",
      "37584\n",
      "2761\n",
      "45808\n",
      "14851\n",
      ">> Train: [30][1/4]\tTime 15.841 (15.841)\tData 0.263 (0.263)\tLoss 0.0263 (0.0263)\n",
      ">> Train: [30][4/4]\tTime 1.752 (11.350)\tData 0.000 (0.068)\tLoss 0.0040 (0.0204)\n",
      ">> Val: [30][1/4]\tTime 3.604 (3.604)\tAccu 1.000\n",
      ">> Val: [30][4/4]\tTime 0.359 (2.244)\tAccu 0.975\n",
      "74223\n",
      "2373\n",
      "30554\n",
      "31470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a9ea79349e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# train for one epoch on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e3dce5081f6b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# do one step for multiple batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    text_meta, text_img = gen_text_img(num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "    dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "\n",
    "    index_converter = IndexConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "    train_dataset = InMemoryDigitsDataset(mode='train',text=text_meta,img=text_img,total=num,\n",
    "                                      transform=transform, converter = index_converter)\n",
    "    dev_dataset = InMemoryDigitsDataset(mode='dev', text=dev_meta, img=dev_img, total=dev_num,\n",
    "                                    transform=transform, converter = index_converter)\n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "    dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=collate_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "batch_100_acc=[0.85,0.9,0.75,0.9,0.85,0.9,0.9,0.7,0.95,1,0.95,0.9,1,1,0.95,1,0.7,1,0.95,1,1,0.95,1,0.95,1,0.95,1,0.9,1,1]\n",
    "batch_200_acc=[0.805,0.85,0.91,0.91,0.965,0.96,0.995,0.99,0.98,1,0.975,0.945,0.985,0.985,0.970,0.960,0.970,0.935,0.99,0.96,0.975,0.97,0.98,0.99,0.97,0.975,1,1,0.975]\n",
    "batch_400_acc=[]\n",
    "batch_800_acc=[]\n",
    "# feature_set_random_acc=[0.953,0.950,0.969,0.960,0.980,0.985,0.975]\n",
    "# feature_set_zero_acc=[0.9,0.98,0.92,0.92,1,0.98,1]\n",
    "# feature_set_random_acc=[0.8,0.9,0.9,0.85,0.8,0.9,0.95]\n",
    "x= [i for i in range(0,30)]\n",
    "plt.plot(x,batch_100_acc,color = 'b',label=\"batch_100\")\n",
    "plt.plot(x,batch_200_acc,color = 'r',label=\"batch_200\")\n",
    "plt.plot(x,batch_400_acc,color = 'g',label=\"batch_400\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch=100\n",
    "import matplotlib.pyplot as plt\n",
    "feature8_set_random_acc=[0.05,0.05,0.05,0.15,0.25,0.25,0.25,0.25,0.5,0.6,0.45,0.75,0.65,0.55,0.85,0.75,0.55,0.7,0.65,0.65,0.65,0.65,0.75,0.7,0.85,0.45,0.8,0.8,0.7,0.6]\n",
    "classifier_set_random_acc=[0,0,0.05,0,0.15,0.1,0.2,0.4,0.35,0.35,0.55,0.45,0.45,0.7,0.3,0.5,0.4,0.25,0.65,0.85,0.35,0.4,0.55,0.5,0.7,0.5,0.4,0.45,0.7,0.55]\n",
    "not_modifited_acc=[0.85,0.9,0.75,0.9,0.85,0.9,0.9,0.7,0.95,1,0.95,0.9,1,1,0.95,1,0.7,1,0.95,1,1,0.95,1,0.95,1,0.95,1,0.9,1,1]\n",
    "x= [i for i in range(0,30)]\n",
    "plt.plot(x,feature8_set_random_acc,color = 'b',label=\"feature8_set_random\")\n",
    "plt.plot(x,classifier_set_random_acc,color = 'r',label=\"classifier_set_random\")\n",
    "plt.plot(x,not_modifited_acc,color = 'g',label=\"param_not_modifited\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
