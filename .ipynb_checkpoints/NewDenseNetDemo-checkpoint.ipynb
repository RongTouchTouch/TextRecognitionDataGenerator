{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter, IndexConverter\n",
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "from generate import gen_text_img\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "from models.densenet_ import DenseNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs targets ready for the network.\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        target_lengths = sample.target_lengths.to(device)\n",
    "        targets = sample.targets # Expected targets to have CPU Backend\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        images = sample.images\n",
    "        if isinstance(images, tuple):\n",
    "            targets = targets.to(device)\n",
    "            log_probs = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image).squeeze(1)\n",
    "                log_probs.append(log_prob)\n",
    "            input_lengths = torch.IntTensor([i.size(0) for i in log_probs]).to(device)\n",
    "            log_probs = pad_sequence(log_probs)\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            #log_probs = pad_sequence(log_probs)\n",
    "            input_lengths = torch.full((images.size(0),), log_probs.size(0), dtype=torch.int32, device=device)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        if isinstance(images, tuple):\n",
    "            preds = []\n",
    "            for image in images:\n",
    "                image = image.unsqueeze(0).to(device)\n",
    "                log_prob = model(image)\n",
    "                preds.append(converter.best_path_decode(log_prob, strings=False))\n",
    "        else: # Batch\n",
    "            images = images.to(device)\n",
    "            log_probs = model(images)\n",
    "            preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            print(pred)\n",
    "            print(target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# alphabet/alphabet_decode_5990.txt\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--max-epoch','100','--optimizer','rmsprop','--gpu-id','-1','--resume','densenet121_pretrained.pth.tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using pre-trained model 'densenet121'\n",
      "tensor([0.9730, 0.6115, 0.4878, 0.6029, 0.7668, 0.5090, 0.5308, 0.7189, 0.7476,\n",
      "        0.2163, 0.3510, 0.4979, 0.0298, 0.1017, 0.4076, 0.9725, 0.5206, 0.3360,\n",
      "        0.2115, 0.6452, 0.5202, 0.6232, 0.1299, 0.9406, 0.1677, 0.0991, 0.2496,\n",
      "        0.2150, 0.9933, 0.4888, 0.8249, 0.6631, 0.5549, 0.1429, 0.7525, 0.8278,\n",
      "        0.1264, 0.5727, 0.4638, 0.3996, 0.0676, 0.3768, 0.4058, 0.5404, 0.9207,\n",
      "        0.4985, 0.4773, 0.8851, 0.6373, 0.6698, 0.4496, 0.8770, 0.0407, 0.4363,\n",
      "        0.7489, 0.2112, 0.2387, 0.3836, 0.8507, 0.1787, 0.2213, 0.3289, 0.7653,\n",
      "        0.6973, 0.1629, 0.3276, 0.3749, 0.2642, 0.6857, 0.8258, 0.4624, 0.7248,\n",
      "        0.2334, 0.5924, 0.7242, 0.7153, 0.5589, 0.9179, 0.4495, 0.9731, 0.2485,\n",
      "        0.2072, 0.3999, 0.7298, 0.6927, 0.7061, 0.4021, 0.3995, 0.0653, 0.7651,\n",
      "        0.0588, 0.4598, 0.9103, 0.7344, 0.7612, 0.5174, 0.2458, 0.4068, 0.1353,\n",
      "        0.1941, 0.2378, 0.7875, 0.0091, 0.1243, 0.6388, 0.3351, 0.2835, 0.8055,\n",
      "        0.5368, 0.8336, 0.0593, 0.8434, 0.2621, 0.0313, 0.9563, 0.6320, 0.6213,\n",
      "        0.1695, 0.1816, 0.2965, 0.0284, 0.6592, 0.8100, 0.0075, 0.0233, 0.2637,\n",
      "        0.1602, 0.1829, 0.0112, 0.3612, 0.3082, 0.2928, 0.9657, 0.5678, 0.4337,\n",
      "        0.0245, 0.0041, 0.6660, 0.0615, 0.2396, 0.6919, 0.9028, 0.7928, 0.1449,\n",
      "        0.7010, 0.8637, 0.5955, 0.0993, 0.1846, 0.1882, 0.5439, 0.8122, 0.6987,\n",
      "        0.1391, 0.1500, 0.7860, 0.7492, 0.1210, 0.9143, 0.3641, 0.7162, 0.6086,\n",
      "        0.0182, 0.2831, 0.6656, 0.8022, 0.5931, 0.1608, 0.5599, 0.1426, 0.6622,\n",
      "        0.7535, 0.6018, 0.0197, 0.9706, 0.4399, 0.1862, 0.6290, 0.7512, 0.5275,\n",
      "        0.6306, 0.6586, 0.2191, 0.9939, 0.9680, 0.2948, 0.5199, 0.7326, 0.0976,\n",
      "        0.1749, 0.6852, 0.0214, 0.3293, 0.7653, 0.3071, 0.2945, 0.6626, 0.3934,\n",
      "        0.1365, 0.1793, 0.2669, 0.0230, 0.7320, 0.3286, 0.2694, 0.8857, 0.6531,\n",
      "        0.4968, 0.6789, 0.2264, 0.9458, 0.7280, 0.3140, 0.7415, 0.9871, 0.1031,\n",
      "        0.6648, 0.7713, 0.6537, 0.6166, 0.9225, 0.1687, 0.0884, 0.7801, 0.5053,\n",
      "        0.5871, 0.7172, 0.7852, 0.4752, 0.1364, 0.7889, 0.7051, 0.5331, 0.9931,\n",
      "        0.7454, 0.0406, 0.9222, 0.3148, 0.7067, 0.5646, 0.0538, 0.0156, 0.5318,\n",
      "        0.5697, 0.6517, 0.5153, 0.5984, 0.6348, 0.7546, 0.9277, 0.2727, 0.4935,\n",
      "        0.3814, 0.6276, 0.8022, 0.9573, 0.9715, 0.0464, 0.8612, 0.8919, 0.7390,\n",
      "        0.3040, 0.2640, 0.7190, 0.3929, 0.2891, 0.5182, 0.6598, 0.2112, 0.2902,\n",
      "        0.3507, 0.4398, 0.1590, 0.1019, 0.1551, 0.8215, 0.6177, 0.5268, 0.0805,\n",
      "        0.5770, 0.3889, 0.4362, 0.4770, 0.6732, 0.7873, 0.7344, 0.5725, 0.4630,\n",
      "        0.5853, 0.0143, 0.2045, 0.8043, 0.7048, 0.3258, 0.0145, 0.5447, 0.4743,\n",
      "        0.1149, 0.6193, 0.2219, 0.7923, 0.0347, 0.6796, 0.0495, 0.5465, 0.1467,\n",
      "        0.5259, 0.2313, 0.6138, 0.2279, 0.8690, 0.9265, 0.6256, 0.7995, 0.5598,\n",
      "        0.7149, 0.4217, 0.4196, 0.2818, 0.6410, 0.7267, 0.9656, 0.2049, 0.9814,\n",
      "        0.2936, 0.8751, 0.7368, 0.2732, 0.6688, 0.7764, 0.1351, 0.1403, 0.1446,\n",
      "        0.2676, 0.8703, 0.0110, 0.4285, 0.4046, 0.9407, 0.4493, 0.8145, 0.3285,\n",
      "        0.4324, 0.6741, 0.4809, 0.0875, 0.3266, 0.4764, 0.0585, 0.9130, 0.8737,\n",
      "        0.4280, 0.8014, 0.4089, 0.8506, 0.2299, 0.5333, 0.6538, 0.0950, 0.6356,\n",
      "        0.0820, 0.0216, 0.7787, 0.3362, 0.4138, 0.2767, 0.4552, 0.2475, 0.1481,\n",
      "        0.9803, 0.1326, 0.7034, 0.9580, 0.8121, 0.3155, 0.1381, 0.6743, 0.1657,\n",
      "        0.7654, 0.9868, 0.3258, 0.0972, 0.5187, 0.8226])\n"
     ]
    }
   ],
   "source": [
    "global args, device\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "model_params = {}\n",
    "model_params['architecture'] = args.arch\n",
    "model_params['num_classes'] = len(args.alphabet) + 1\n",
    "model_params['mean'] = (0.5,)\n",
    "model_params['std'] = (0.5,)\n",
    "model_params['pretrained'] = args.pretrained\n",
    "model = init_network(model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = 'pretrained/densenet121_pretrained.pth'\n",
    "checkpoint = torch.load(model_path,map_location = 'cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# for i, j in model.named_parameters():\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "idx = random.sample(range(384),384)\n",
    "random_param = torch.rand(384)\n",
    "zero_param = torch.Tensor([0.0]*384)\n",
    "\n",
    "#checkpoint[\"classifier.weight\"] = torch.rand(5990,384)\n",
    "#checkpoint[\"features.8.weight\"] = zero_param\n",
    "checkpoint[\"features.8.weight\"] = random_param\n",
    "#checkpoint[\"features.8.weight\"] = checkpoint[\"features.8.weight\"][idx]\n",
    "#print(checkpoint[\"classifier.weight\"])\n",
    "print(checkpoint[\"features.8.weight\"])\n",
    "\n",
    "torch.save(checkpoint, \"pretrained/weights.pth\")\n",
    "\n",
    "# model = DenseNet(img_height=32, drop_rate=0.2, num_classes=len(args.alphabet) + 1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import InMemoryDigitsDataset, DigitsDataset, collate_train, collate_dev, inmemory_train, inmemory_dev\n",
    "\n",
    "num = 1000\n",
    "dev_num = int(num/5)\n",
    "use_file = 1\n",
    "text_length = 10\n",
    "font_size = 0\n",
    "font_id = 1\n",
    "space_width = 1\n",
    "text_color = '#282828'\n",
    "thread_count = 8\n",
    "\n",
    "random_skew = False\n",
    "skew_angle = 0\n",
    "random_blur = False\n",
    "blur = 0\n",
    "\n",
    "distorsion = 0\n",
    "background = 1\n",
    "\n",
    "# for i in range(100):\n",
    "#     img, label = train_dataset.__getitem__(i)\n",
    "#     print(img.shape,label)\n",
    "# plt.imshow(train_dataset.__getitem__(0)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27072\n",
      "2024\n",
      "3932\n",
      "3416\n",
      ">> Train: [1][1/2]\tTime 27.752 (27.752)\tData 0.121 (0.121)\tLoss 0.3024 (0.3024)\n",
      ">> Train: [1][2/2]\tTime 16.716 (22.234)\tData 0.002 (0.061)\tLoss 0.1323 (0.2174)\n",
      "[587, 263, 643, 3277, 2314, 180, 3429, 70, 1757, 466]\n",
      "[587, 263, 643, 3277, 2314, 180, 3429, 70, 1757, 466]\n",
      "[860, 2040, 1, 52, 5, 168, 9, 4, 178, 473]\n",
      "[860, 2040, 1, 52, 5, 168, 9, 4, 178, 473]\n",
      "[860, 507, 68, 7, 1155, 82, 4324, 1, 49, 5]\n",
      "[860, 507, 68, 7, 1155, 82, 4324, 1, 49, 5]\n",
      "[1264, 310, 1339, 387, 14, 59, 1, 206, 462, 172]\n",
      "[1264, 310, 1339, 387, 14, 59, 1, 206, 462, 172]\n",
      "[66, 3, 151, 42, 99, 38, 643, 3277, 2, 2040]\n",
      "[66, 3, 151, 42, 99, 38, 643, 3277, 2, 2040]\n",
      "[69, 4, 616, 191, 1246, 3, 643, 3277, 232, 128]\n",
      "[69, 4, 616, 191, 1246, 3, 643, 3277, 232, 128]\n",
      "[28, 17, 1010, 56, 803, 803, 880, 21, 1097, 1780]\n",
      "[28, 17, 1010, 56, 803, 803, 880, 21, 1097, 1780]\n",
      "[531, 54, 307, 52, 2072, 2, 643, 3277, 1302, 254]\n",
      "[531, 54, 307, 52, 2072, 2, 643, 3277, 1302, 254]\n",
      "[3698, 3698, 1042, 1042, 51, 281, 387, 34, 243, 2713]\n",
      "[3698, 3698, 1042, 1042, 51, 281, 387, 34, 243, 2713]\n",
      "[127, 191, 102, 1, 151, 42, 99, 907, 16, 217]\n",
      "[127, 191, 102, 1, 151, 42, 99, 907, 16, 217]\n",
      "[1, 304, 110, 406, 66, 348, 2, 151, 131, 3099]\n",
      "[1, 304, 110, 406, 66, 348, 2, 151, 220, 3099]\n",
      "[93, 1097, 1, 716, 129, 608, 264, 2613, 2491, 4006]\n",
      "[93, 1097, 1, 716, 129, 608, 264, 4006, 2491, 4006]\n",
      "[9, 24, 391, 211, 186, 241, 1057, 180, 17, 82]\n",
      "[9, 24, 391, 211, 186, 241, 1057, 180, 17, 82]\n",
      "[645, 337, 905, 446, 21, 1042, 1, 34, 14, 238]\n",
      "[645, 337, 905, 446, 21, 1042, 1, 34, 14, 238]\n",
      "[2491, 2, 549, 545, 3, 565, 180, 549, 612, 1]\n",
      "[2491, 2, 549, 545, 3, 565, 180, 549, 612, 1]\n",
      "[394, 30, 1, 553, 4, 618, 2188, 238, 4, 618]\n",
      "[394, 30, 1, 553, 4, 618, 2188, 238, 4, 618]\n",
      "[17, 549, 2924, 2924, 142, 407, 151, 42, 99, 1]\n",
      "[17, 549, 2924, 2924, 407, 151, 42, 99, 1]\n",
      "[531, 110, 238, 293, 407, 608, 34, 2040, 549, 1]\n",
      "[531, 110, 238, 407, 608, 34, 2040, 549, 1]\n",
      "[151, 42, 99, 859, 1347, 1339, 34, 238, 394, 1]\n",
      "[151, 42, 99, 859, 1347, 1339, 34, 238, 394, 1]\n",
      "[240, 184, 184, 5, 1035, 8, 238, 138, 2040, 860]\n",
      "[240, 184, 184, 5, 1035, 8, 238, 138, 2040, 860]\n",
      ">> Val: [1][1/1]\tTime 2.372 (2.372)\tAccu 0.800\n",
      ">>>> save best model at epoch: 1\n",
      "30388\n",
      "3416\n",
      "884\n",
      "840\n",
      ">> Train: [2][1/2]\tTime 26.693 (26.693)\tData 0.198 (0.198)\tLoss 0.1461 (0.1461)\n",
      ">> Train: [2][2/2]\tTime 15.096 (20.894)\tData 0.003 (0.100)\tLoss 0.0193 (0.0827)\n",
      "[8, 1722, 560, 2, 629, 225, 1, 11, 56, 121]\n",
      "[8, 1722, 560, 2, 629, 225, 1, 11, 56, 121]\n",
      "[15, 2, 120, 128, 581, 480, 446, 446, 43, 660]\n",
      "[15, 2, 120, 128, 581, 480, 446, 446, 43, 660]\n",
      "[363, 58, 77, 101, 3, 54, 8, 183, 24, 588]\n",
      "[363, 58, 77, 101, 3, 54, 8, 183, 24, 588]\n",
      "[1, 54, 529, 264, 63, 486, 350, 2, 359, 535]\n",
      "[1, 54, 529, 264, 63, 486, 350, 2, 359, 535]\n",
      "[11, 454, 446, 2, 30, 225, 1, 664, 75, 9]\n",
      "[11, 454, 446, 2, 30, 225, 1, 664, 75, 9]\n",
      "[1, 329, 159, 638, 8, 348, 1245, 21, 30, 1]\n",
      "[1, 329, 159, 638, 8, 348, 1245, 21, 30, 1]\n",
      "[74, 4, 187, 16, 217, 3, 16, 217, 9, 128]\n",
      "[74, 4, 187, 16, 217, 3, 16, 217, 9, 128]\n",
      "[367, 24, 204, 473, 1, 24, 24, 100, 115, 69]\n",
      "[367, 24, 204, 473, 1, 24, 24, 100, 115, 69]\n",
      "[286, 230, 120, 1061, 142, 956, 65, 5, 44, 2]\n",
      "[286, 230, 120, 1061, 956, 65, 5, 44, 2]\n",
      "[151, 204, 473, 1, 235, 5, 120, 87, 102, 1454]\n",
      "[151, 204, 473, 1, 235, 5, 120, 87, 102, 1454]\n",
      "[16, 217, 2, 980, 1721, 1132, 361, 1, 9, 4]\n",
      "[16, 217, 2, 980, 1721, 1132, 361, 1, 9, 4]\n",
      "[100, 38, 348, 2, 120, 1061, 338, 34, 1007, 3786]\n",
      "[100, 38, 348, 2, 120, 1061, 338, 34, 1007, 3786]\n",
      "[709, 1881, 1329, 2, 17, 1158, 569, 3, 8, 23]\n",
      "[709, 1881, 1329, 2, 17, 1158, 569, 3, 8, 23]\n",
      "[172, 453, 3, 8, 102, 599, 2, 30, 513, 1]\n",
      "[172, 453, 3, 8, 102, 599, 2, 30, 513, 1]\n",
      "[709, 1158, 569, 15, 2, 4, 3282, 251, 694, 1152]\n",
      "[709, 1158, 569, 15, 2, 4, 3282, 251, 1152]\n",
      "[21, 3, 348, 880, 8, 183, 157, 338, 34, 148]\n",
      "[21, 3, 348, 880, 8, 183, 157, 338, 34, 148]\n",
      "[64, 1, 9, 4, 24, 243, 2713, 1, 243, 2713]\n",
      "[64, 1, 9, 4, 24, 243, 2713, 1, 243, 2713]\n",
      "[151, 42, 99, 230, 230, 33, 34, 23, 709, 1158]\n",
      "[151, 42, 99, 230, 230, 33, 34, 23, 709, 1158]\n",
      "[569, 1, 880, 8, 500, 1894, 2, 243, 2713, 618]\n",
      "[569, 1, 880, 8, 500, 1894, 2, 243, 2713, 618]\n",
      "[1541, 2, 30, 513, 1, 54, 299, 40, 4, 232]\n",
      "[1541, 2, 30, 513, 1, 54, 299, 40, 4, 232]\n",
      ">> Val: [2][1/1]\tTime 2.680 (2.680)\tAccu 0.900\n",
      ">>>> save best model at epoch: 2\n",
      "23484\n",
      "18589\n",
      "1585\n",
      "799\n",
      ">> Train: [3][1/2]\tTime 19.901 (19.901)\tData 0.180 (0.180)\tLoss 0.0146 (0.0146)\n",
      ">> Train: [3][2/2]\tTime 12.398 (16.149)\tData 0.001 (0.091)\tLoss 0.0220 (0.0183)\n",
      "[7, 1356, 2, 5, 1, 9, 4, 159, 1, 151]\n",
      "[7, 1356, 2, 5, 1, 9, 4, 159, 1, 151]\n",
      "[220, 277, 1, 220, 277, 481, 168, 9, 713, 93]\n",
      "[220, 277, 1, 220, 277, 481, 168, 9, 713, 93]\n",
      "[51, 21, 1, 49, 462, 4, 64, 70, 54, 1962]\n",
      "[51, 21, 1, 49, 462, 4, 64, 70, 54, 1962]\n",
      "[42, 99, 1512, 40, 213, 232, 151, 226, 156, 325]\n",
      "[42, 99, 1512, 40, 213, 232, 151, 226, 156, 325]\n",
      "[5, 220, 277, 1100, 51, 4, 64, 70, 8, 243]\n",
      "[5, 220, 277, 1100, 51, 4, 64, 70, 8, 243]\n",
      "[34, 14, 243, 2713, 157, 3, 151, 42, 99, 213]\n",
      "[34, 14, 243, 2713, 157, 3, 151, 42, 99, 213]\n",
      "[630, 834, 834, 51, 2592, 180, 220, 277, 1, 52]\n",
      "[630, 834, 834, 51, 2592, 180, 220, 277, 1, 52]\n",
      "[1, 1597, 69, 843, 121, 567, 14, 3, 1597, 180]\n",
      "[1, 1597, 69, 843, 121, 567, 14, 3, 1597, 180]\n",
      "[2713, 157, 54, 168, 490, 473, 14, 3, 150, 18]\n",
      "[2713, 157, 54, 168, 490, 473, 14, 3, 150, 18]\n",
      "[348, 2, 226, 157, 1, 49, 5, 1249, 34, 14]\n",
      "[348, 2, 226, 157, 1, 49, 5, 1249, 34, 14]\n",
      "[264, 730, 1, 151, 42, 99, 54, 1597, 14, 190]\n",
      "[264, 730, 1, 151, 42, 99, 54, 1597, 14, 190]\n",
      "[243, 2713, 157, 2, 243, 172, 453, 1, 184, 7]\n",
      "[243, 2713, 157, 2, 243, 172, 453, 1, 184, 7]\n",
      "[1597, 180, 1, 151, 42, 99, 716, 129, 608, 264]\n",
      "[1597, 180, 1, 151, 42, 99, 716, 129, 608, 264]\n",
      "[33, 1, 348, 2, 1597, 549, 459, 33, 459, 17]\n",
      "[33, 1, 348, 2, 1597, 549, 459, 33, 459, 17]\n",
      "[42, 99, 1, 1179, 23, 5, 734, 211, 2491, 165]\n",
      "[42, 99, 1, 1179, 23, 5, 734, 211, 2491]\n",
      "[3, 407, 608, 14, 23, 382, 1, 151, 42, 99]\n",
      "[3, 407, 608, 14, 23, 382, 1, 151, 42, 99]\n",
      "[9, 11, 17, 549, 78, 407, 4169, 2045, 1]\n",
      "[9, 11, 17, 549, 78, 407, 4169, 2045, 1]\n",
      "[645, 326, 608, 14, 100, 36, 121, 1851, 2, 2045]\n",
      "[645, 326, 608, 14, 100, 36, 121, 1851, 2, 2045]\n",
      "[315, 334, 395, 480, 1, 240, 1560, 500, 845, 78]\n",
      "[315, 334, 395, 480, 1, 240, 1560, 500, 845, 78]\n",
      "[1179, 23, 215, 4463, 612, 17, 1597, 1, 54, 529]\n",
      "[1179, 23, 215, 4407, 4718, 17, 1597, 1, 54, 529]\n",
      ">> Val: [3][1/1]\tTime 3.261 (3.261)\tAccu 0.900\n",
      ">>>> save best model at epoch: 3\n",
      "5637\n",
      "25397\n",
      "871\n",
      "1921\n",
      ">> Train: [4][1/2]\tTime 21.566 (21.566)\tData 0.321 (0.321)\tLoss 0.0515 (0.0515)\n",
      ">> Train: [4][2/2]\tTime 12.839 (17.202)\tData 0.001 (0.161)\tLoss 0.0290 (0.0402)\n",
      "[74, 4, 187, 16, 217, 3, 16, 217, 9, 128]\n",
      "[74, 4, 187, 16, 217, 3, 16, 217, 9, 128]\n",
      "[11, 454, 446, 2, 30, 225, 1, 664, 75, 9]\n",
      "[11, 454, 446, 2, 30, 225, 1, 664, 75, 9]\n",
      "[363, 58, 77, 101, 3, 54, 8, 183, 24, 588]\n",
      "[363, 58, 77, 101, 3, 54, 8, 183, 24, 588]\n",
      "[8, 1722, 560, 2, 629, 225, 1, 11, 56, 121]\n",
      "[8, 1722, 560, 2, 629, 225, 1, 11, 56, 121]\n",
      "[367, 24, 204, 473, 1, 24, 24, 100, 115, 69]\n",
      "[367, 24, 204, 473, 1, 24, 24, 100, 115, 69]\n",
      "[286, 230, 120, 1061, 142, 956, 65, 5, 44, 2]\n",
      "[286, 230, 120, 1061, 956, 65, 5, 44, 2]\n",
      "[15, 2, 120, 128, 581, 480, 446, 446, 43, 660]\n",
      "[15, 2, 120, 128, 581, 480, 446, 446, 43, 660]\n",
      "[1, 54, 529, 264, 63, 486, 350, 2, 359, 535]\n",
      "[1, 54, 529, 264, 63, 486, 350, 2, 359, 535]\n",
      "[1, 329, 159, 638, 8, 348, 1245, 21, 30, 1]\n",
      "[1, 329, 159, 638, 8, 348, 1245, 21, 30, 1]\n",
      "[151, 204, 473, 1, 235, 5, 120, 87, 102, 1454]\n",
      "[151, 204, 473, 1, 235, 5, 120, 87, 102, 1454]\n",
      "[100, 38, 348, 2, 120, 1061, 338, 34, 1007, 3786]\n",
      "[100, 38, 348, 2, 120, 1061, 338, 34, 1007, 3786]\n",
      "[709, 1881, 1329, 2, 17, 1158, 569, 3, 8, 23]\n",
      "[709, 1881, 1329, 2, 17, 1158, 569, 3, 8, 23]\n",
      "[16, 217, 2, 980, 1721, 1132, 361, 1, 9, 4]\n",
      "[16, 217, 2, 980, 1721, 1132, 361, 1, 9, 4]\n",
      "[709, 1158, 569, 15, 2, 4, 3282, 251, 694, 1152]\n",
      "[709, 1158, 569, 15, 2, 4, 3282, 251, 1152]\n",
      "[64, 1, 9, 4, 24, 243, 2713, 1, 243, 2713]\n",
      "[64, 1, 9, 4, 24, 243, 2713, 1, 243, 2713]\n",
      "[21, 3, 348, 880, 8, 183, 157, 338, 34, 148]\n",
      "[21, 3, 348, 880, 8, 183, 157, 338, 34, 148]\n",
      "[172, 453, 3, 8, 102, 599, 2, 30, 513, 1]\n",
      "[172, 453, 3, 8, 102, 599, 2, 30, 513, 1]\n",
      "[151, 42, 99, 230, 230, 33, 34, 23, 709, 1158]\n",
      "[151, 42, 99, 230, 230, 33, 34, 23, 709, 1158]\n",
      "[569, 1, 880, 8, 500, 1894, 2, 243, 2713, 618]\n",
      "[569, 1, 880, 8, 500, 1894, 2, 243, 2713, 618]\n",
      "[1541, 2, 30, 513, 1, 54, 299, 40, 4, 232]\n",
      "[1541, 2, 30, 513, 1, 54, 299, 40, 4, 232]\n",
      ">> Val: [4][1/1]\tTime 3.561 (3.561)\tAccu 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> save best model at epoch: 4\n",
      "7163\n",
      "16037\n",
      "3220\n",
      "7\n",
      ">> Train: [5][1/2]\tTime 20.214 (20.214)\tData 0.423 (0.423)\tLoss 0.0129 (0.0129)\n",
      ">> Train: [5][2/2]\tTime 11.916 (16.065)\tData 0.001 (0.212)\tLoss 0.0363 (0.0246)\n",
      "[407, 128, 2, 1, 359, 128, 14, 1, 407, 151]\n",
      "[407, 128, 2, 1, 359, 128, 14, 1, 407, 151]\n",
      "[2713, 157, 1, 28, 65, 44, 643, 3277, 4, 190]\n",
      "[2713, 157, 1, 28, 65, 44, 643, 3277, 4, 190]\n",
      "[407, 151, 42, 99, 682, 129, 1647, 21, 23, 211]\n",
      "[407, 151, 42, 99, 682, 129, 1647, 21, 23, 211]\n",
      "[307, 29, 2, 220, 277, 4742, 40, 33, 1, 145]\n",
      "[307, 29, 2, 220, 277, 2897, 40, 33, 1, 145]\n",
      "[643, 3277, 69, 34, 14, 151, 42, 99, 2, 509]\n",
      "[643, 3277, 69, 34, 14, 151, 42, 99, 2, 509]\n",
      "[4205, 4205, 860, 1, 734, 211, 52, 43, 244, 11]\n",
      "[4205, 4205, 860, 1, 734, 211, 52, 43, 244, 11]\n",
      "[2, 4, 737, 35, 282, 29, 100, 849, 181, 3]\n",
      "[2, 4, 737, 35, 282, 29, 100, 849, 181, 3]\n",
      "[42, 99, 78, 1, 407, 232, 35, 145, 581, 167]\n",
      "[42, 99, 78, 1, 407, 232, 35, 145, 581, 167]\n",
      "[1021, 31, 57, 1, 307, 893, 2087, 446, 243, 157]\n",
      "[1021, 31, 57, 1, 307, 893, 2087, 446, 243, 157]\n",
      "[74, 14, 7, 17, 4, 36, 473, 1, 643, 3277]\n",
      "[74, 14, 7, 17, 4, 36, 473, 1, 643, 3277]\n",
      "[643, 3277, 52, 403, 660, 2646, 2, 1, 587, 1089]\n",
      "[643, 3277, 52, 403, 660, 2646, 2, 1, 587, 1089]\n",
      "[4, 1764, 1, 54, 939, 160, 14, 243, 2713, 3]\n",
      "[4, 1764, 1, 54, 939, 160, 14, 243, 2713, 3]\n",
      "[1136, 51, 21, 3, 151, 42, 99, 136, 281, 264]\n",
      "[1136, 51, 21, 3, 151, 42, 99, 136, 281, 264]\n",
      "[1647, 157, 2259, 180, 220, 277, 1, 1568, 40, 14]\n",
      "[1647, 157, 2259, 180, 220, 277, 1, 1568, 40, 14]\n",
      "[78, 1, 121, 157, 481, 240, 407, 23, 232]\n",
      "[78, 1, 121, 157, 481, 240, 407, 23, 232]\n",
      "[348, 307, 220, 277, 3723, 14, 190, 33, 1, 2028]\n",
      "[348, 307, 220, 277, 3723, 14, 190, 33, 1, 2028]\n",
      "[243, 103, 1, 129, 57, 307, 220, 277, 1961, 8]\n",
      "[243, 103, 1, 129, 57, 307, 220, 277, 1961, 8]\n",
      "[78, 591, 119, 293, 44, 232, 800, 3010, 8, 243]\n",
      "[78, 591, 119, 44, 232, 800, 3010, 8, 243]\n",
      "[34, 14, 55, 219, 121, 523, 2, 1207, 439, 1]\n",
      "[34, 14, 55, 219, 121, 523, 2, 1207, 439, 1]\n",
      "[121, 157, 330, 193, 9, 63, 72, 725, 14, 3]\n",
      "[121, 157, 330, 193, 9, 63, 72, 725, 14, 3]\n",
      ">> Val: [5][1/1]\tTime 2.836 (2.836)\tAccu 0.900\n",
      ">>>> save best model at epoch: 5\n",
      "1585\n",
      "815\n",
      "5487\n",
      "2014\n",
      ">> Train: [6][1/2]\tTime 23.416 (23.416)\tData 0.422 (0.422)\tLoss 0.0729 (0.0729)\n",
      ">> Train: [6][2/2]\tTime 11.368 (17.392)\tData 0.001 (0.211)\tLoss 0.0122 (0.0426)\n",
      "[3, 407, 151, 42, 99, 479, 74, 156, 307, 238]\n",
      "[3, 407, 151, 42, 99, 479, 74, 156, 307, 238]\n",
      "[16, 217, 608, 14, 31, 57, 38, 151, 42, 99]\n",
      "[16, 217, 608, 14, 31, 57, 38, 151, 42, 99]\n",
      "[327, 110, 1, 643, 3277, 3698, 3698, 1042, 1042, 51]\n",
      "[327, 110, 1, 643, 3277, 3698, 3698, 1042, 1042, 51]\n",
      "[549, 860, 119, 1, 407, 307, 29, 1379, 34, 145]\n",
      "[549, 860, 119, 1, 407, 307, 29, 1379, 34, 145]\n",
      "[216, 1, 531, 156, 110, 238, 354, 44, 93, 33]\n",
      "[216, 1, 531, 156, 110, 238, 354, 44, 93, 33]\n",
      "[78, 1, 407, 145, 346, 7, 43, 341, 49, 148]\n",
      "[78, 1, 407, 145, 346, 7, 43, 341, 49, 148]\n",
      "[151, 42, 99, 608, 14, 2332, 69, 50, 2748, 1]\n",
      "[151, 42, 99, 608, 14, 2332, 69, 50, 2748, 1]\n",
      "[99, 33, 34, 1090, 187, 80, 1, 325, 180, 17]\n",
      "[99, 33, 34, 1090, 187, 80, 1, 325, 180, 17]\n",
      "[93, 14, 238, 1, 129, 57, 907, 180, 151, 42]\n",
      "[93, 14, 238, 1, 129, 57, 907, 180, 151, 42]\n",
      "[16, 217, 481, 3265, 3044, 348, 638, 643, 3277, 78]\n",
      "[16, 217, 481, 3265, 3044, 348, 638, 643, 3277, 78]\n",
      "[2, 156, 244, 3, 643, 3277, 245, 378, 8, 14]\n",
      "[2, 156, 244, 3, 643, 3277, 245, 378, 8, 14]\n",
      "[1179, 2, 151, 220, 3099, 70, 458, 74, 33, 4]\n",
      "[1179, 2, 151, 220, 3099, 70, 458, 74, 33, 4]\n",
      "[2517, 70, 21, 1, 52, 121, 157, 7, 359, 72]\n",
      "[2517, 70, 21, 1, 52, 121, 157, 7, 359, 72]\n",
      "[725, 1, 240, 34, 1780, 70, 21, 156, 3, 21]\n",
      "[725, 1, 240, 34, 1780, 70, 21, 156, 3, 21]\n",
      "[14, 1780, 70, 31, 57, 281, 78, 1, 407, 307]\n",
      "[14, 1780, 70, 31, 57, 281, 78, 1, 407, 307]\n",
      "[178, 473, 128, 1003, 165, 23, 215, 29, 56, 54]\n",
      "[178, 473, 128, 1003, 23, 215, 29, 56, 54]\n",
      "[52, 25, 4, 531, 473, 686, 2491, 3, 407, 172]\n",
      "[52, 25, 4, 531, 473, 686, 2491, 3, 407, 172]\n",
      "[3099, 70, 458, 14, 74, 156, 3, 643, 3277, 686]\n",
      "[3099, 70, 458, 14, 74, 156, 3, 643, 3277, 686]\n",
      "[515, 129, 1, 151, 42, 99, 172, 7, 155, 581]\n",
      "[515, 129, 1, 151, 42, 99, 172, 7, 155, 581]\n",
      "[23, 211, 244, 1, 52, 348, 114, 5, 307, 220]\n",
      "[23, 211, 244, 1, 52, 348, 114, 5, 307, 220]\n",
      ">> Val: [6][1/1]\tTime 3.428 (3.428)\tAccu 0.950\n",
      ">>>> save best model at epoch: 6\n",
      "25062\n",
      "2024\n",
      "0\n",
      "765\n",
      ">> Train: [7][1/2]\tTime 19.468 (19.468)\tData 0.453 (0.453)\tLoss 0.0056 (0.0056)\n",
      ">> Train: [7][2/2]\tTime 10.535 (15.001)\tData 0.002 (0.227)\tLoss 0.0037 (0.0047)\n",
      "[569, 201, 19, 118, 105, 46, 1609, 19, 105, 76]\n",
      "[569, 201, 5565, 118, 105, 46, 1609, 5565, 105, 76]\n",
      "[48, 198, 820, 1688, 868, 352, 569, 201, 19, 118]\n",
      "[5745, 198, 820, 1688, 868, 352, 569, 201, 5565, 118]\n",
      "[352, 569, 1253, 965, 1, 1174, 237, 440, 868, 352]\n",
      "[352, 569, 1253, 965, 1, 1174, 237, 440, 868, 352]\n",
      "[44, 56, 100, 5, 398, 16, 192, 162, 124, 37]\n",
      "[44, 56, 100, 5, 398, 16, 192, 162, 124, 37]\n",
      "[631, 266, 434, 808, 61, 3, 40, 274, 524, 166]\n",
      "[631, 266, 434, 808, 61, 3, 40, 274, 524, 166]\n",
      "[507, 17, 37, 196, 932, 1, 19, 105, 73, 19]\n",
      "[507, 17, 37, 196, 932, 1, 5565, 105, 73, 5565]\n",
      "[473, 1255, 79, 59, 1022, 1255, 382, 266, 249, 201]\n",
      "[473, 1255, 79, 59, 1022, 1255, 382, 266, 249, 201]\n",
      "[37, 37, 122, 703, 1, 281, 97, 8, 837, 1205]\n",
      "[37, 37, 122, 703, 1, 281, 97, 8, 837, 1205]\n",
      "[59, 1022, 1, 744, 664, 8, 401, 433, 1472, 17]\n",
      "[59, 1022, 1, 744, 664, 8, 401, 433, 1472, 17]\n",
      "[26, 97, 30, 58, 18, 352, 569, 237, 37, 322]\n",
      "[26, 97, 30, 58, 18, 352, 569, 237, 37, 322]\n",
      "[322, 374, 3, 44, 2512, 412, 97, 808, 58, 253]\n",
      "[322, 374, 3, 44, 2512, 412, 97, 808, 58, 253]\n",
      "[433, 506, 368, 1025, 83, 53, 28, 298, 352, 1073]\n",
      "[433, 506, 368, 1025, 83, 53, 28, 298, 352, 1073]\n",
      "[19, 105, 46, 118, 26, 40, 123, 57, 4, 848]\n",
      "[5565, 105, 46, 118, 26, 40, 123, 57, 4, 848]\n",
      "[1, 412, 22, 19, 76, 1353, 488, 92, 198, 3]\n",
      "[1, 412, 22, 5565, 76, 1353, 488, 92, 198, 3]\n",
      "[205, 205, 205, 205, 205, 125, 176, 1353, 1]\n",
      "[71, 71, 71, 71, 71, 71, 125, 176, 1353, 1]\n",
      "[65, 15, 2, 253, 1846, 1617, 1231, 249, 10, 253]\n",
      "[65, 15, 2, 253, 1846, 1617, 1231, 249, 10, 253]\n",
      "[175, 58, 18, 294, 385, 285, 16, 473, 1255, 687]\n",
      "[175, 58, 18, 294, 385, 285, 16, 473, 1255, 687]\n",
      "[493, 1452, 42, 99, 249, 10, 253, 151, 676, 2154]\n",
      "[493, 1452, 42, 99, 249, 10, 253, 151, 676, 2154]\n",
      "[249, 10, 253, 1362, 990, 2, 151, 1121, 2407, 249]\n",
      "[249, 10, 253, 1362, 990, 2, 151, 1121, 2407, 249]\n",
      "[523, 2, 1468, 53, 3, 116, 138, 1, 352, 569]\n",
      "[523, 2, 1468, 53, 3, 116, 138, 1, 352, 569]\n",
      ">> Val: [7][1/1]\tTime 3.336 (3.336)\tAccu 0.700\n",
      "21229\n",
      "9703\n",
      "4758\n",
      "765\n",
      ">> Train: [8][1/2]\tTime 21.163 (21.163)\tData 0.548 (0.548)\tLoss 0.0201 (0.0201)\n",
      ">> Train: [8][2/2]\tTime 9.916 (15.540)\tData 0.001 (0.274)\tLoss 0.0092 (0.0147)\n",
      "[9, 24, 981, 11, 35, 307, 145, 1412, 479, 1080]\n",
      "[9, 24, 981, 11, 35, 307, 145, 1412, 479, 1080]\n",
      "[23, 24, 215, 70, 165, 321, 7, 5, 238, 138]\n",
      "[23, 24, 215, 70, 321, 7, 5, 238, 138]\n",
      "[407, 617, 70, 1, 145, 734, 211, 36, 2332, 58]\n",
      "[407, 617, 70, 1, 145, 734, 211, 36, 2332, 58]\n",
      "[407, 3456, 29, 2, 128, 1904, 1904, 1, 969]\n",
      "[407, 3456, 29, 2, 128, 1904, 1904, 1, 969]\n",
      "[643, 3277, 3, 407, 407, 643, 3277, 240, 582, 145]\n",
      "[643, 3277, 3, 407, 407, 643, 3277, 240, 582, 145]\n",
      "[407, 1343, 1, 7, 5, 2, 1, 407, 151, 42]\n",
      "[407, 1343, 1, 7, 5, 2, 1, 407, 151, 42]\n",
      "[981, 11, 1, 49, 5, 4, 232, 1143, 1926, 2]\n",
      "[981, 11, 1, 49, 5, 4, 232, 1143, 1926, 2]\n",
      "[99, 387, 849, 78, 1, 407, 7, 5, 391, 211]\n",
      "[99, 387, 849, 78, 1, 407, 7, 5, 391, 211]\n",
      "[102, 1, 29, 34, 1158, 569, 157, 156, 14, 3]\n",
      "[102, 1, 29, 34, 1158, 569, 157, 156, 14, 3]\n",
      "[1, 220, 277, 1249, 34, 243, 2713, 157, 156, 14]\n",
      "[1, 220, 277, 1249, 34, 243, 2713, 157, 156, 14]\n",
      "[880, 8, 243, 2713, 618, 21, 1207, 2, 30, 513]\n",
      "[880, 8, 243, 2713, 618, 21, 1207, 2, 30, 513]\n",
      "[1, 45, 5, 29, 54, 1597, 14, 3, 29, 1597]\n",
      "[1, 45, 5, 29, 54, 1597, 14, 3, 29, 1597]\n",
      "[69, 172, 843, 121, 1, 643, 3277, 54, 1404, 29]\n",
      "[69, 172, 843, 121, 1, 643, 3277, 54, 1404, 29]\n",
      "[307, 220, 277, 2897, 14, 21, 33, 3, 150, 18]\n",
      "[307, 220, 277, 2897, 14, 21, 33, 3, 150, 18]\n",
      "[1, 29, 54, 849, 181, 14, 1, 52, 5, 29]\n",
      "[1, 29, 54, 849, 181, 14, 1, 52, 5, 29]\n",
      "[643, 3277, 550, 282, 29, 244, 44, 2, 1094, 613]\n",
      "[643, 3277, 550, 282, 29, 244, 44, 2, 1094, 613]\n",
      "[731, 507, 473, 168, 9, 240, 34, 1, 44, 36]\n",
      "[731, 507, 473, 168, 9, 240, 34, 1, 44, 36]\n",
      "[211, 560, 2, 384, 34, 23, 473, 33, 3, 77]\n",
      "[211, 560, 2, 384, 34, 23, 473, 33, 3, 77]\n",
      "[8, 44, 54, 8, 238, 138, 874, 1, 240, 35]\n",
      "[8, 44, 54, 8, 238, 138, 874, 1, 240, 35]\n",
      "[144, 243, 2713, 157, 2242, 40, 33, 1, 2242, 23]\n",
      "[144, 243, 2713, 157, 2242, 40, 33, 1, 2242, 23]\n",
      ">> Val: [8][1/1]\tTime 3.825 (3.825)\tAccu 0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> save best model at epoch: 8\n",
      "23651\n",
      "31270\n",
      "3843\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-202:\n",
      "Process ForkPoolWorker-201:\n",
      "Process ForkPoolWorker-203:\n",
      "Process ForkPoolWorker-204:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a9ea79349e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                           blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n\u001b[1;32m     30\u001b[0m     dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n\u001b[0;32m---> 31\u001b[0;31m                           blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mindex_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TextRecognitionDataGenerator/generate.py\u001b[0m in \u001b[0;36mgen_text_img\u001b[0;34m(num, use_file, text_length, font_size, font_id, space_width, background, text_color, blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_strings_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mmutex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36mPool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0;32m--> 119\u001b[0;31m                     context=self.get_context())\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mRawValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         self._worker_handler = threading.Thread(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    text_meta, text_img = gen_text_img(num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "    dev_meta, dev_img = gen_text_img(dev_num, use_file, text_length, font_size, font_id, space_width, background, text_color,\n",
    "                          blur, random_blur, distorsion, skew_angle, random_skew, thread_count)\n",
    "\n",
    "    index_converter = IndexConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "    train_dataset = InMemoryDigitsDataset(mode='train',text=text_meta,img=text_img,total=num,\n",
    "                                      transform=transform, converter = index_converter)\n",
    "    dev_dataset = InMemoryDigitsDataset(mode='dev', text=dev_meta, img=dev_img, total=dev_num,\n",
    "                                    transform=transform, converter = index_converter)\n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "    dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=collate_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
