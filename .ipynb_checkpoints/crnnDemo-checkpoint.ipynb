{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils.converter import LabelConverter\n",
    "from datasets.dataset import DigitsDataset, collate_train, collate_dev\n",
    "\n",
    "import models\n",
    "from models.crnn import init_network\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('./d9ata/runs')\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "optimizer_names = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "def parse_args():\n",
    "    '''Parse input arguments.'''\n",
    "    parser = argparse.ArgumentParser(description='Digit Recognition')\n",
    "    parser.add_argument('--dataset-root', default='./data',\n",
    "                        help='train dataset path')\n",
    "    parser.add_argument('--arch', default='mobilenetv2_cifar', choices=model_names,\n",
    "                        help='model architecture: {} (default: mobilenetv2_cifar)'.format(' | '.join(model_names)))\n",
    "    parser.add_argument('--gpu-id', type=int, default=-1,\n",
    "                        help='gpu called when train')\n",
    "    parser.add_argument('--alphabet', default='0123456789',\n",
    "                        help='label alphabet, string format or file')\n",
    "    parser.add_argument('--optimizer', default='rmsprop', choices=optimizer_names,\n",
    "                        help='optimizer options: {} (default: rmsprop)'.format(' | '.join(optimizer_names)))\n",
    "    parser.add_argument('--max-epoch', type=int, default='30',\n",
    "                        help='number of total epochs to run (default: 30)')\n",
    "    parser.add_argument('--not-pretrained', dest='pretrained', action='store_false',\n",
    "                        help='initialize model with random weights (default: pretrained on cifar10)')\n",
    "    parser.add_argument('--validate-interval', type=int, default=1,\n",
    "                        help='Interval to be displayed')\n",
    "    parser.add_argument('--save-interval', type=int, default=1,\n",
    "                        help='save a model')\n",
    "    parser.add_argument('--workers', default=4, type=int,\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='batch size to train a model')\n",
    "    parser.add_argument('--train-samples', default=640000, type=int,\n",
    "                        help='train sample number')\n",
    "    parser.add_argument('--image-size', type=int, default=32,\n",
    "                        help='maximum size of longer image side used for training (default: 32)')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--decay-rate', type=float, default=0.1,\n",
    "                        help='learning rate decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4,\n",
    "                        help='weight decay (default: 5e-4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                        help='print frequency (default: 10)')\n",
    "    parser.add_argument('--directory', metavar='EXPORT_DIR', default='./checkpoint',\n",
    "                        help='Where to store samples and models')\n",
    "    parser.add_argument('--rnn', action='store_true',\n",
    "                        help='Train the model with model of rnn')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='FILENAME',\n",
    "                        help='name of the latest checkpoint (default: None)')\n",
    "    parser.add_argument('--test-only', action='store_true',\n",
    "                        help='test only')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets, target_lengths) in enumerate(train_loader):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        target_lengths = sample.target_lengths\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. Get our inputs images ready for the network.\n",
    "        images = images.to(device)\n",
    "        # targets is a list of `torch.IntTensor` with `batch_size` size.\n",
    "        # Expected targets to have CPU Backend\n",
    "        target_lengths = target_lengths.to(device)\n",
    "\n",
    "        # step 3. Run out forward pass.\n",
    "        log_probs = model(images)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters\n",
    "        # by calling optimizer.step()\n",
    "        input_lengths = torch.full((images.shape[0],), log_probs.shape[0], dtype=torch.int32, device=device)\n",
    "        print(input_lengths)\n",
    "        loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step for multiple batches\n",
    "        # accumulated gradients are used\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(train_loader):\n",
    "            print('>> Train: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                   epoch+1, i+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dev_loader, model, epoch, converter):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_verified = 0\n",
    "    end = time.time()\n",
    "\n",
    "    #for i, (images, targets) in enumerate(dev_loader):\n",
    "    for i, sample in enumerate(dev_loader):\n",
    "        images = sample.images\n",
    "        targets = sample.targets\n",
    "        images = images.to(device)\n",
    "        log_probs = model(images)\n",
    "        preds = converter.best_path_decode(log_probs, strings=False)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        num_verified += len(targets)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            print('pred:',pred)\n",
    "            print('target',target)\n",
    "            if pred == target:\n",
    "                num_correct += 1\n",
    "        accuracy.update(num_correct / num_verified)\n",
    "\n",
    "        if (i+1) % args.print_freq == 0 or i == 0 or (i+1) == len(dev_loader):\n",
    "            print('>> Val: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Accu {accuracy.val:.3f}'.format(\n",
    "                   epoch+1, i+1, len(dev_loader), batch_time=batch_time, accuracy=accuracy))\n",
    "\n",
    "    return accuracy.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(state, is_best, directory):\n",
    "    filename = os.path.join(directory, '{}_epoch_{}.pth.tar'.format(state['arch'], state['epoch']))\n",
    "    with contextlib.suppress(FileNotFoundError):\n",
    "        os.remove(filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('>>>> save best model at epoch: {}'.format(state['epoch']))\n",
    "        filename_best = os.path.join(directory, '{}_best.pth.tar'.format(state['arch']))\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            os.remove(filename_best)\n",
    "        shutil.copyfile(filename, filename_best)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def set_batchnorm_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        # freeze running mean and std:\n",
    "        # we do training one image at a time\n",
    "        # so the statistics would not be per batch\n",
    "        # hence we choose freezing (ie using imagenet statistics)\n",
    "        m.eval()\n",
    "        # # freeze parameters:\n",
    "        # # in fact no need to freeze scale and bias\n",
    "        # # they can be learned\n",
    "        # # that is why next two lines are commented\n",
    "        # for p in m.parameters():\n",
    "            # p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = ['main.py','--dataset-root','alphabet','--arch','densenet121','--alphabet','alphabet/alphabet_decode_5990.txt',\n",
    "            '--lr','5e-5','--optimizer','rmsprop','--max-epoch','100','--gpu-id','-1','--not-pretrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating directory if it does not exist:\n",
      ">> './checkpoint/densenet121_rmsprop_lr5.0e-05_wd5.0e-04_bsize64_imsize32'\n",
      ">> Using model from scratch (random weights) 'densenet121'\n",
      "torch.Size([3, 32, 280]) tensor([ 455,   18,   12,  195,   80, 1421,   13,    1,  119,   20],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([  6,  76,  94, 675,  76,  19,   6,   6,  19,  46], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([ 17,  90,  62,  58, 477,   2, 902, 309, 224, 351], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([  5,   1,  49, 253, 601, 319, 243, 723, 249, 332], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([  1, 416, 329, 105,  24, 120,  16,  11,  15,  54], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([ 937,  741,  945, 1847,  290,   68,  544,  449,  386,  261],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([  9, 163, 599, 238, 214,  39,   1,   4, 153, 338], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([128,  19,  73,  10,  19,  46,  10,  19, 118,  10], dtype=torch.int32)\n",
      "torch.Size([3, 32, 280]) tensor([   4,   60,  821, 4424,    1, 1304,  194,   44,   56,    2],\n",
      "       dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0164030748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f016ea119b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = parse_args()\n",
    "\n",
    "if args.gpu_id < 0:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create export dir if it doesnt exist\n",
    "directory = \"{}\".format(args.arch)\n",
    "directory += \"_{}_lr{:.1e}_wd{:.1e}\".format(args.optimizer, args.lr, args.weight_decay)\n",
    "directory += \"_bsize{}_imsize{}\".format(args.batch_size, args.image_size)\n",
    "\n",
    "args.directory = os.path.join(args.directory, directory)\n",
    "print(\">> Creating directory if it does not exist:\\n>> '{}'\".format(args.directory))\n",
    "if not os.path.exists(args.directory):\n",
    "    os.makedirs(args.directory)\n",
    "\n",
    "# initialize model\n",
    "if args.pretrained:\n",
    "    print(\">> Using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    print(\">> Using model from scratch (random weights) '{}'\".format(args.arch))\n",
    "\n",
    "# load alphabet from file\n",
    "if os.path.isfile(args.alphabet):\n",
    "    alphabet = ''\n",
    "    with open(args.alphabet, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            alphabet += line.strip()\n",
    "    args.alphabet = alphabet\n",
    "\n",
    "model_params = {}\n",
    "model_params['architecture'] = args.arch\n",
    "model_params['num_classes'] = len(args.alphabet) + 1\n",
    "model_params['mean'] = (0.5,)\n",
    "model_params['std'] = (0.5,)\n",
    "model_params['pretrained'] = args.pretrained\n",
    "model = init_network(model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 280)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=model.meta['mean'], std=model.meta['std']),\n",
    "])\n",
    "#\n",
    "train_dataset = DigitsDataset(mode='train', data_root=args.dataset_root, transform=transform)\n",
    "dev_dataset = DigitsDataset(mode='dev', data_root=args.dataset_root, transform=transform)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=collate_train,\n",
    "                               shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "dev_loader = data.DataLoader(dev_dataset, batch_size=args.batch_size, collate_fn=collate_dev,\n",
    "                             shuffle=False, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "for i in range(1,10):\n",
    "        img, label = train_loader.dataset.__getitem__(i)\n",
    "        print(img.shape,label)\n",
    "plt.imshow(train_loader.dataset.__getitem__(2)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [1][1/1]\tTime 2.082 (2.082)\tData 0.080 (0.080)\tLoss 27.1716 (27.1716)\n",
      "pred: [2021, 3107, 3839, 3107]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [2021, 3107, 3839, 3107]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [2021, 3107, 3839, 3107]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [2021, 3107, 2522, 3107, 3839, 3107, 3839, 2571, 3839, 2769]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [344, 3107, 3839, 3107, 3839, 3107, 3839, 2769]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [1][1/1]\tTime 0.494 (0.494)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [2][1/1]\tTime 2.965 (2.965)\tData 0.107 (0.107)\tLoss 26.5042 (26.5042)\n",
      "pred: [1763, 3107, 1183, 3839, 1797, 3107, 3839, 1183, 2571, 3107, 2571, 1183, 2571, 3107, 1183, 3107, 3839, 1797, 3839, 1740]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1763, 3107, 1183, 3839, 1797, 3107, 3839, 1183, 2571, 3107, 2571, 1183, 2571, 3107, 1183, 3107, 3839, 1797, 3839, 1740]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1763, 3107, 1797, 3839, 1183, 1797, 3107, 2571, 1183, 3839, 3107, 3839, 3107, 1797, 3839, 3107, 1797, 3839, 3107, 1183, 2571, 3107, 2571, 1797, 3839, 1740]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1763, 3107, 3839, 1183, 3107, 3839, 1797, 3107, 2571, 1183, 2571, 1183, 2571, 3107, 1183, 2571, 1797, 3107]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1763, 2522, 3107, 1183, 3107, 1183, 3839, 2571, 1797, 1183, 3107, 2571, 1183, 3107, 1797, 3839, 1183, 3839, 2571, 1797, 39, 1740]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [2][1/1]\tTime 0.524 (0.524)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [3][1/1]\tTime 2.903 (2.903)\tData 0.109 (0.109)\tLoss 26.0614 (26.0614)\n",
      "pred: [1763, 2522, 3107, 1797, 3107, 1797, 3107, 1797, 2571, 1797, 3107, 1797, 39]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1763, 2522, 3107, 1797, 3107, 1797, 3107, 1797, 2571, 1797, 3107, 1797, 39]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1763, 3107, 1797, 1183, 1797, 1183, 1797, 1183, 2571, 1797, 1183, 1797, 1740]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1763, 2522, 3107, 1183, 1797, 3107, 1797, 2571, 1797, 3107, 1797, 3107]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1763, 2571, 3107, 1183, 3107, 1797, 1183, 1797, 2571, 1797, 3107, 1797, 3107, 1797, 4707]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [3][1/1]\tTime 0.461 (0.461)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [4][1/1]\tTime 2.914 (2.914)\tData 0.119 (0.119)\tLoss 25.7437 (25.7437)\n",
      "pred: [1763, 3107, 637, 1797, 3107, 1797, 4707]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1763, 3107, 637, 1797, 3107, 1797, 4707]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1763, 2522, 3107, 637, 1797]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1763, 1797, 3107, 1797, 637, 1797, 3107, 637, 3107, 1797, 3107, 1797]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1763, 3107, 1797, 3107, 1797, 3107, 1797, 3107, 637, 3107, 1797, 1740]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [4][1/1]\tTime 0.450 (0.450)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [5][1/1]\tTime 2.827 (2.827)\tData 0.127 (0.127)\tLoss 25.4916 (25.4916)\n",
      "pred: [1, 1797, 3107, 637, 1797, 4707]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 1797, 3107, 637, 1797, 4707]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 1797, 39]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 1797, 3107, 637, 3107]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 1797, 3107, 1797, 637, 1797, 637, 1797]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [5][1/1]\tTime 0.583 (0.583)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [6][1/1]\tTime 3.144 (3.144)\tData 0.127 (0.127)\tLoss 25.2317 (25.2317)\n",
      "pred: [1, 1797, 3107, 1797]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 1797, 3107, 1797]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 1797, 3107, 1797, 1, 1797]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 1797, 3107, 1797, 1, 4707]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 1797, 1, 1797, 3107, 1797]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [6][1/1]\tTime 0.566 (0.566)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [7][1/1]\tTime 2.735 (2.735)\tData 0.139 (0.139)\tLoss 25.0501 (25.0501)\n",
      "pred: [1, 1797, 3107, 1797, 1, 1797, 3107, 1797, 3107, 1, 1797]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 1797, 3107, 1797, 1, 1797, 3107, 1797, 3107, 1, 1797]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 1797, 3107, 1797, 3107, 1, 1797]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 1797, 1, 1797, 1, 1797, 39, 1, 4707]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 1797, 1, 1797]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [7][1/1]\tTime 0.500 (0.500)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [8][1/1]\tTime 2.862 (2.862)\tData 0.111 (0.111)\tLoss 24.8785 (24.8785)\n",
      "pred: [1, 39, 1797, 3107, 1797, 1, 1797, 1, 1797, 3107, 1797, 1, 1797, 3107, 1]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 39, 1797, 3107, 1797, 1, 1797, 1, 1797, 3107, 1797, 1, 1797, 3107, 1]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 1797, 1, 1797, 3107, 1797, 15, 1, 1797, 3107, 1797]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 1797, 39, 1797, 3107, 1, 1797, 20, 1, 1797, 2, 1, 1797, 1, 290]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 1797, 1, 1797, 3107, 1797, 1, 1797, 1, 1797, 1, 1797, 4707]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [8][1/1]\tTime 0.545 (0.545)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [9][1/1]\tTime 3.209 (3.209)\tData 0.123 (0.123)\tLoss 24.7348 (24.7348)\n",
      "pred: [1, 1797, 1, 1797, 39, 1, 39, 15, 1, 1797, 3107, 1797, 1, 1797, 1, 20, 1, 261, 1797, 1, 39, 1]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 1797, 1, 1797, 39, 1, 39, 15, 1, 1797, 3107, 1797, 1, 1797, 1, 20, 1, 261, 1797, 1, 39, 1]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 1797, 1, 1797, 1, 1797, 1, 1797, 1, 39, 1797, 1, 1797, 1, 1797, 637, 15, 1, 3107, 1, 599]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 39, 1797, 39, 1, 1797, 39, 1797, 39, 1797, 637, 1797, 1, 1797, 1, 2, 1, 1797, 1, 2, 1, 4707]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 1797, 1, 769, 1797, 3107, 1, 1797, 449, 1, 15, 1, 1797, 1, 1797, 1, 1797, 39, 1, 1797, 4707]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [9][1/1]\tTime 0.594 (0.594)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [10][1/1]\tTime 3.109 (3.109)\tData 0.135 (0.135)\tLoss 24.6045 (24.6045)\n",
      "pred: [1, 39, 449, 1797, 39, 1, 20, 2, 15, 1, 1797, 1, 1797, 1, 1797, 1, 39, 1, 20, 1, 4707]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 39, 449, 1797, 39, 1, 20, 2, 15, 1, 1797, 1, 1797, 1, 1797, 1, 39, 1, 20, 1, 4707]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [20, 1, 449, 1, 15, 1, 449, 1, 39, 1, 637, 1797, 1, 2, 1, 1797, 1, 15, 1, 599, 1, 39, 1, 20]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 39, 449, 1797, 1, 1797, 1, 39, 1, 599, 449, 1797, 637, 1, 599, 1, 2, 1, 39, 1, 2, 1, 20]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 2638, 1, 1797, 15, 1, 15, 1, 15, 1, 39, 1797, 1, 599, 1, 1797, 39, 1, 1797, 1, 1797, 4707]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [10][1/1]\tTime 0.542 (0.542)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [11][1/1]\tTime 3.116 (3.116)\tData 0.124 (0.124)\tLoss 24.4908 (24.4908)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [599, 1, 20, 39, 1, 1797, 1, 20, 2, 15, 1, 637, 1, 599, 1, 20, 39, 1]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 20, 39, 1, 1797, 1, 20, 2, 15, 1, 637, 1, 599, 1, 20, 39, 1]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 20, 1, 449, 1, 599, 1, 39, 1, 637, 2638, 1, 39, 1, 449, 1, 15, 1, 599, 1, 20]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [599, 39, 449, 1, 637, 1, 599, 449, 1, 449, 1, 599, 449, 261, 1, 39, 1, 2, 1, 20]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 2638, 1, 1797, 39, 1, 15, 1, 15, 1, 39, 1, 599, 1, 39, 1, 15, 1, 39, 5, 20, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [11][1/1]\tTime 0.512 (0.512)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [12][1/1]\tTime 2.759 (2.759)\tData 0.114 (0.114)\tLoss 24.3903 (24.3903)\n",
      "pred: [599, 1, 1134, 20, 39, 5, 15, 599, 39, 1, 20, 449, 15, 1, 39, 1, 637, 1, 599, 1, 20, 1847, 1, 2638, 1, 15, 1]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 1134, 20, 39, 5, 15, 599, 39, 1, 20, 449, 15, 1, 39, 1, 637, 1, 599, 1, 20, 1847, 1, 2638, 1, 15, 1]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 20, 261, 1, 15, 449, 1, 599, 1, 5, 1, 637, 1, 449, 1, 15, 1, 15, 599, 1, 5, 1, 20]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 39, 449, 1, 599, 1, 449, 1, 39, 1, 599, 1, 599, 20, 637, 1, 599, 1, 20, 3364]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 39, 1, 15, 20, 1, 449, 1, 5, 599, 1, 599, 1, 20, 39, 1, 15, 1, 39, 5, 1, 599, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [12][1/1]\tTime 0.539 (0.539)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [13][1/1]\tTime 3.128 (3.128)\tData 0.129 (0.129)\tLoss 24.3031 (24.3031)\n",
      "pred: [599, 1, 20, 249, 5, 15, 637, 39, 449, 20, 449, 15, 1, 15, 20, 449, 1, 637, 1, 20, 637, 1, 2638, 1, 449, 599]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 20, 249, 5, 15, 637, 39, 449, 20, 449, 15, 1, 15, 20, 449, 1, 637, 1, 20, 637, 1, 2638, 1, 449, 599]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 20, 261, 1, 599, 120, 1, 120, 1, 5, 1, 2, 1, 5, 1, 15, 1, 15, 599, 1, 5, 1, 20]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 15, 1, 5, 1, 599, 1, 2, 15, 1, 5, 20, 1, 599, 20, 637, 1, 599, 1, 1431]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 15, 1, 449, 1, 39, 20, 15, 120, 1, 449, 1, 5, 599, 1, 5, 1, 599, 1, 249, 1, 449, 1, 449, 5, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [13][1/1]\tTime 0.549 (0.549)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [14][1/1]\tTime 3.009 (3.009)\tData 0.115 (0.115)\tLoss 24.2325 (24.2325)\n",
      "pred: [599, 1, 20, 249, 5, 15, 120, 39, 449, 20, 449, 15, 1, 120, 1, 15, 20, 449, 1, 20, 637, 1, 449, 1, 261, 599]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 20, 249, 5, 15, 120, 39, 449, 20, 449, 15, 1, 120, 1, 15, 20, 449, 1, 20, 637, 1, 449, 1, 261, 599]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 261, 1, 599, 120, 15, 120, 1, 5, 1, 599, 5, 1, 5, 2, 1, 5, 1, 15, 1, 15, 599, 20, 5, 599, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 5, 1, 599, 1, 5, 1, 15, 1, 599, 20, 261, 1, 261, 637, 1, 599, 1, 5]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 449, 1, 449, 20, 1, 15, 120, 1, 449, 1, 5, 599, 1, 5, 1, 599, 1, 249, 1, 449, 1, 5, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [14][1/1]\tTime 0.526 (0.526)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [15][1/1]\tTime 3.077 (3.077)\tData 0.125 (0.125)\tLoss 24.1758 (24.1758)\n",
      "pred: [599, 1, 637, 249, 449, 120, 5, 449, 20, 449, 15, 120, 15, 20, 261, 1, 12, 5, 1, 599, 1, 249, 637, 1, 449, 1, 5, 599]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 637, 249, 449, 120, 5, 449, 20, 449, 15, 120, 15, 20, 261, 1, 12, 5, 1, 599, 1, 249, 637, 1, 449, 1, 5, 599]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 249, 637, 15, 120, 1, 15, 1, 5, 599, 1, 599, 1, 5, 1, 5, 1, 15, 120, 5, 599, 20, 449, 599, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 5, 1, 599, 1, 15, 1, 5, 1, 637, 1, 15, 1, 599, 20, 39, 1, 599, 1, 20, 261, 637, 1, 599, 1, 5]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 449, 1, 449, 261, 1, 15, 120, 1, 449, 1, 5, 599, 1, 5, 15, 599, 1, 249, 1, 15, 1, 5, 20, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [15][1/1]\tTime 0.501 (0.501)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [16][1/1]\tTime 2.900 (2.900)\tData 0.107 (0.107)\tLoss 24.1206 (24.1206)\n",
      "pred: [599, 1, 249, 449, 15, 120, 5, 449, 599, 449, 15, 120, 1, 15, 1, 15, 1, 12, 5, 1, 599, 1, 249, 637, 1, 5, 599]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 249, 449, 15, 120, 5, 449, 599, 449, 15, 120, 1, 15, 1, 15, 1, 12, 5, 1, 599, 1, 249, 637, 1, 5, 599]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 261, 1, 449, 120, 15, 449, 5, 599, 1, 449, 599, 120, 637, 5, 261, 1, 5, 1, 15, 120, 5, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 5, 599, 449, 1, 15, 5, 1, 5, 637, 1, 15, 120, 5, 599, 20, 261, 15, 1, 637, 15, 637, 1, 599, 1, 599]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 449, 1, 449, 15, 1, 15, 120, 1, 449, 1, 5, 599, 15, 1, 599, 1, 249, 1, 15, 1, 5, 20, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [16][1/1]\tTime 0.625 (0.625)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [17][1/1]\tTime 3.094 (3.094)\tData 0.188 (0.188)\tLoss 24.0705 (24.0705)\n",
      "pred: [599, 1, 1543, 449, 15, 637, 449, 599, 449, 15, 120, 1, 15, 120, 15, 1, 12, 5, 1, 599, 1, 249, 637, 5, 1, 5, 599, 120]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 1543, 449, 15, 637, 449, 599, 449, 15, 120, 1, 15, 120, 15, 1, 12, 5, 1, 599, 1, 249, 637, 5, 1, 5, 599, 120]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [1, 261, 449, 120, 449, 15, 449, 5, 1, 449, 15, 120, 1, 5, 120, 1847, 1, 5, 1, 15, 120, 5, 599, 449, 1, 15, 261]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 5, 120, 449, 1, 15, 5, 1, 5, 1847, 120, 15, 120, 5, 599, 20, 449, 15, 1, 15, 599, 637, 12, 637, 599, 1, 599]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 1, 449, 1, 637, 15, 1, 15, 120, 1, 15, 449, 1, 5, 1, 15, 449, 1, 599, 1, 599, 1, 1797, 1, 15, 1, 449, 5, 20, 1, 599]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [17][1/1]\tTime 0.474 (0.474)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [18][1/1]\tTime 2.812 (2.812)\tData 0.111 (0.111)\tLoss 24.0268 (24.0268)\n",
      "pred: [599, 1, 637, 1543, 599, 449, 261, 449, 599, 449, 15, 120, 261, 15, 120, 15, 1, 15, 5, 1, 599, 1, 249, 637, 5, 120, 5, 599, 15]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 637, 1543, 599, 449, 261, 449, 599, 449, 15, 120, 261, 15, 120, 15, 1, 15, 5, 1, 599, 1, 249, 637, 5, 120, 5, 599, 15]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 261, 449, 120, 1, 5, 15, 1, 5, 599, 1, 449, 15, 120, 1, 5, 15, 1847, 1, 5, 1, 15, 449, 15, 5, 599, 449, 1, 15, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 5, 120, 449, 1, 449, 1, 5, 637, 5, 1847, 120, 1, 5, 120, 5, 15, 1, 39, 15, 1, 15, 599, 637, 1, 637, 5, 449, 1]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [599, 12, 449, 1, 637, 261, 1, 15, 120, 15, 449, 1, 5, 599, 15, 637, 599, 1, 1797, 1, 15, 1, 449, 5, 20, 1, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [18][1/1]\tTime 0.451 (0.451)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [19][1/1]\tTime 2.939 (2.939)\tData 0.113 (0.113)\tLoss 23.9885 (23.9885)\n",
      "pred: [1, 15, 637, 261, 449, 15, 599, 449, 120, 449, 15, 120, 261, 15, 599, 1, 5, 1, 249, 637, 5, 120, 5, 1, 13]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 15, 637, 261, 449, 15, 599, 449, 120, 449, 15, 120, 261, 15, 599, 1, 5, 1, 249, 637, 5, 120, 5, 1, 13]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 261, 5, 120, 1, 449, 15, 1, 5, 120, 1, 599, 15, 120, 5, 15, 1847, 599, 637, 120, 15, 449, 15, 5, 599, 449, 1, 15, 261]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 449, 120, 449, 1, 15, 1, 15, 5, 1, 120, 1, 5, 120, 5, 15, 1, 39, 1, 15, 599, 637, 1, 637, 5, 449, 1, 637, 1]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 120, 15, 1, 599, 449, 15, 120, 15, 449, 1, 5, 599, 15, 637, 1, 599, 637, 1797, 449, 15, 449, 15, 20, 1, 4707]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [19][1/1]\tTime 0.550 (0.550)\tAccu 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [20][1/1]\tTime 3.055 (3.055)\tData 0.115 (0.115)\tLoss 23.9545 (23.9545)\n",
      "pred: [1, 599, 637, 39, 449, 599, 449, 261, 15, 120, 261, 15, 1, 261, 1, 15, 5, 1, 249, 637, 5, 120, 599, 13]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [1, 599, 637, 39, 449, 599, 449, 261, 15, 120, 261, 15, 1, 261, 1, 15, 5, 1, 249, 637, 5, 120, 599, 13]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 599, 637, 261, 120, 1, 449, 15, 449, 5, 1, 599, 15, 120, 5, 15, 1847, 599, 637, 120, 1, 15, 120, 5, 599, 449, 5, 15, 261]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 1, 120, 449, 1, 449, 1, 120, 5, 1, 120, 1, 15, 120, 12, 5, 120, 39, 15, 1, 15, 599, 637, 1797, 637, 5, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 15, 1, 449, 15, 120, 1, 15, 449, 1, 15, 599, 15, 637, 1, 599, 637, 1797, 449, 15, 449, 15, 261, 449, 15, 1, 15]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [20][1/1]\tTime 0.484 (0.484)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [21][1/1]\tTime 2.959 (2.959)\tData 0.129 (0.129)\tLoss 23.9248 (23.9248)\n",
      "pred: [599, 1, 599, 637, 39, 449, 637, 449, 15, 261, 637, 15, 637, 1, 15, 599, 1, 261, 1, 15, 5, 1, 637, 5, 120, 599, 13]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 599, 637, 39, 449, 637, 449, 15, 261, 637, 15, 637, 1, 15, 599, 1, 261, 1, 15, 5, 1, 637, 5, 120, 599, 13]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 15, 637, 261, 637, 351, 120, 261, 449, 15, 449, 120, 1, 599, 120, 449, 5, 15, 1847, 599, 637, 120, 15, 253, 5, 599, 449, 5, 15, 261]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 1, 120, 449, 1, 120, 5, 449, 1, 15, 120, 1, 449, 12, 5, 120, 253, 15, 1, 15, 599, 637, 1797, 637, 5, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 1, 449, 15, 120, 1, 15, 449, 120, 15, 637, 1, 599, 1, 599, 637, 1797, 449, 15, 449, 637, 449, 15, 1, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [21][1/1]\tTime 0.590 (0.590)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [22][1/1]\tTime 3.184 (3.184)\tData 0.121 (0.121)\tLoss 23.8988 (23.8988)\n",
      "pred: [599, 1, 599, 637, 39, 449, 637, 449, 15, 261, 637, 15, 637, 68, 15, 599, 1, 261, 1, 15, 5, 1, 599, 637, 253, 120, 15, 599, 13]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 599, 637, 39, 449, 637, 449, 15, 261, 637, 15, 637, 68, 15, 599, 1, 261, 1, 15, 5, 1, 599, 637, 253, 120, 15, 599, 13]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 599, 637, 39, 637, 351, 120, 261, 449, 15, 449, 120, 1, 15, 120, 449, 5, 15, 1847, 599, 637, 120, 15, 120, 253, 5, 599, 449, 5, 15]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 261, 120, 449, 1, 15, 120, 5, 449, 15, 5, 15, 1, 449, 5, 120, 253, 15, 5, 15, 599, 637, 120, 637, 5, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 120, 1, 449, 15, 120, 1, 15, 449, 120, 15, 449, 599, 1, 599, 637, 1797, 449, 637, 15, 449, 1, 449, 15, 1, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [22][1/1]\tTime 0.528 (0.528)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [23][1/1]\tTime 2.841 (2.841)\tData 0.103 (0.103)\tLoss 23.8759 (23.8759)\n",
      "pred: [599, 1, 599, 637, 39, 449, 253, 449, 15, 120, 449, 261, 599, 68, 15, 599, 1, 261, 1, 15, 5, 1, 449, 1, 5, 599, 637, 253, 120, 15, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 599, 637, 39, 449, 253, 449, 15, 120, 449, 261, 599, 68, 15, 599, 1, 261, 1, 15, 5, 1, 449, 1, 5, 599, 637, 253, 120, 15, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 1, 599, 637, 39, 637, 449, 120, 253, 449, 15, 449, 120, 1, 13, 599, 120, 449, 5, 120, 1847, 599, 637, 15, 120, 253, 5, 599, 449, 5, 15]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 261, 120, 449, 1, 120, 5, 449, 15, 5, 15, 1, 449, 5, 120, 1421, 15, 1, 15, 599, 637, 120, 637, 5, 449, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 15, 449, 1, 449, 20, 449, 1, 120, 1, 13, 637, 120, 15, 449, 15, 449, 599, 5, 1, 599, 449, 1797, 449, 15, 449, 68, 449, 1, 15, 1, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [23][1/1]\tTime 0.542 (0.542)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [24][1/1]\tTime 3.142 (3.142)\tData 0.134 (0.134)\tLoss 23.8557 (23.8557)\n",
      "pred: [599, 1, 599, 637, 39, 449, 253, 449, 15, 120, 449, 261, 599, 68, 1, 599, 1, 261, 13, 1, 15, 1, 449, 1, 12, 599, 637, 253, 120, 15, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 599, 637, 39, 449, 253, 449, 15, 120, 449, 261, 599, 68, 1, 599, 1, 261, 13, 1, 15, 1, 449, 1, 12, 599, 637, 253, 120, 15, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 637, 599, 637, 39, 637, 449, 261, 39, 637, 120, 449, 120, 5, 1, 599, 120, 637, 5, 120, 1847, 599, 120, 1, 449, 120, 1, 5, 599, 449, 5, 15]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 261, 599, 1, 15, 120, 5, 449, 15, 5, 1, 599, 261, 120, 15, 5, 120, 1421, 15, 1, 15, 599, 637, 120, 637, 5, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 15, 449, 1, 5, 449, 20, 449, 1, 5, 1, 637, 253, 15, 449, 15, 449, 599, 1, 599, 449, 15, 449, 1, 261, 1, 15, 338, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [24][1/1]\tTime 0.543 (0.543)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [25][1/1]\tTime 2.895 (2.895)\tData 0.117 (0.117)\tLoss 23.8376 (23.8376)\n",
      "pred: [599, 1, 449, 637, 39, 449, 253, 449, 15, 261, 449, 261, 599, 253, 1, 5, 1, 253, 1, 15, 1, 449, 1, 12, 637, 253, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 449, 637, 39, 449, 253, 449, 15, 261, 449, 261, 599, 253, 1, 5, 1, 253, 1, 15, 1, 449, 1, 12, 637, 253, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 637, 599, 449, 39, 637, 449, 261, 39, 637, 120, 449, 120, 5, 1, 599, 120, 637, 5, 15, 1847, 599, 1, 449, 120, 1, 5, 599, 449, 5, 15, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 68, 120, 1, 15, 120, 5, 599, 1, 15, 5, 1, 599, 15, 120, 15, 5, 1, 1421, 15, 1, 15, 599, 637, 120, 637, 1, 449, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 15, 449, 1, 5, 449, 20, 1, 637, 1, 15, 637, 449, 15, 449, 15, 449, 599, 1, 599, 637, 449, 249, 5, 15, 449, 253, 261, 1, 15, 338, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [25][1/1]\tTime 0.514 (0.514)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [26][1/1]\tTime 3.152 (3.152)\tData 0.133 (0.133)\tLoss 23.8216 (23.8216)\n",
      "pred: [599, 1, 449, 637, 39, 449, 637, 20, 449, 15, 261, 449, 261, 599, 68, 1, 5, 15, 253, 1, 15, 1, 449, 1, 599, 637, 253, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 1, 449, 637, 39, 449, 637, 20, 449, 15, 261, 449, 261, 599, 68, 1, 5, 15, 253, 1, 15, 1, 449, 1, 599, 637, 253, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 637, 15, 449, 39, 431, 449, 261, 1, 637, 1847, 449, 120, 637, 15, 13, 599, 120, 637, 5, 15, 1847, 599, 120, 1, 449, 15, 1, 5, 599, 449, 5, 15, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 5, 120, 449, 1, 15, 120, 5, 599, 449, 15, 5, 15, 599, 15, 449, 1, 5, 1, 1421, 15, 1, 15, 599, 637, 1, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 15, 449, 1, 120, 449, 68, 1, 637, 45, 15, 449, 1, 15, 449, 1, 20, 1, 599, 449, 15, 5, 15, 449, 637, 261, 1, 15, 338, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [26][1/1]\tTime 0.613 (0.613)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [27][1/1]\tTime 3.175 (3.175)\tData 0.190 (0.190)\tLoss 23.8073 (23.8073)\n",
      "pred: [599, 449, 637, 39, 599, 449, 20, 449, 15, 1, 261, 599, 12, 1, 5, 15, 253, 1, 449, 15, 1, 449, 1, 15, 12, 599, 637, 253, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 449, 637, 39, 599, 449, 20, 449, 15, 1, 261, 599, 12, 1, 5, 15, 253, 1, 449, 15, 1, 449, 1, 15, 12, 599, 637, 253, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 637, 15, 449, 39, 431, 120, 449, 1, 1847, 68, 253, 637, 20, 13, 599, 120, 15, 5, 15, 1847, 637, 599, 120, 1, 449, 15, 1, 20, 599, 15, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 5, 120, 449, 1, 15, 120, 5, 599, 1, 15, 599, 5, 449, 1, 5, 1, 1421, 15, 1, 15, 599, 637, 1, 253, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 1, 253, 1, 1421, 1, 431, 15, 449, 15, 637, 1, 3095, 68, 15, 1, 449, 249, 5, 15, 253, 261, 1, 15, 1, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [27][1/1]\tTime 0.601 (0.601)\tAccu 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [28][1/1]\tTime 3.097 (3.097)\tData 0.141 (0.141)\tLoss 23.7947 (23.7947)\n",
      "pred: [599, 449, 1, 39, 599, 449, 20, 449, 15, 261, 1, 261, 599, 12, 1, 449, 15, 253, 1, 15, 1, 449, 1, 12, 599, 637, 253, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 449, 1, 39, 599, 449, 20, 449, 15, 261, 1, 261, 599, 12, 1, 449, 15, 253, 1, 15, 1, 449, 1, 12, 599, 637, 253, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 637, 15, 449, 39, 449, 120, 1, 15, 68, 1, 637, 20, 13, 637, 120, 15, 5, 15, 1847, 637, 15, 120, 1, 599, 15, 1, 20, 599, 15, 1]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 637, 5, 120, 449, 1, 15, 120, 637, 599, 253, 15, 76, 1, 599, 5, 449, 1, 5, 1, 1421, 15, 1, 15, 599, 1, 637, 253, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 1, 253, 1, 1421, 449, 431, 15, 449, 253, 449, 1, 68, 15, 1, 449, 68, 5, 1, 637, 261, 1, 163, 338, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [28][1/1]\tTime 0.506 (0.506)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [29][1/1]\tTime 2.905 (2.905)\tData 0.116 (0.116)\tLoss 23.7836 (23.7836)\n",
      "pred: [599, 449, 249, 599, 449, 20, 449, 15, 261, 1, 449, 599, 261, 1, 449, 15, 253, 5, 1, 253, 1, 449, 1, 12, 599, 449, 253, 449, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 449, 249, 599, 449, 20, 449, 15, 261, 1, 449, 599, 261, 1, 449, 15, 253, 5, 1, 253, 1, 449, 1, 12, 599, 449, 253, 449, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 261, 599, 449, 39, 449, 120, 1, 637, 15, 68, 637, 1, 637, 120, 15, 5, 68, 637, 1, 599, 15, 1, 20, 599, 15, 253]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 5, 120, 449, 1421, 1, 15, 120, 637, 599, 253, 15, 5, 1, 599, 15, 449, 1, 5, 1, 1421, 15, 1, 15, 599, 1, 12, 253, 637, 1, 599, 637, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 1, 253, 1, 637, 1, 253, 15, 449, 253, 449, 68, 1, 309, 15, 1, 599, 637, 1, 449, 249, 68, 5, 68, 637, 261, 449, 163, 338, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [29][1/1]\tTime 0.568 (0.568)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n",
      ">> Train: [30][1/1]\tTime 2.932 (2.932)\tData 0.113 (0.113)\tLoss 23.7737 (23.7737)\n",
      "pred: [599, 449, 249, 599, 449, 20, 449, 15, 1, 449, 599, 261, 1, 599, 15, 253, 68, 15, 1, 449, 1, 12, 599, 253, 15, 253, 309]\n",
      "target [35, 50, 27, 45, 637, 1543, 210, 10, 431, 426]\n",
      "pred: [599, 449, 249, 599, 449, 20, 449, 15, 1, 449, 599, 261, 1, 599, 15, 253, 68, 15, 1, 449, 1, 12, 599, 253, 15, 253, 309]\n",
      "target [455, 18, 12, 195, 80, 1421, 13, 1, 119, 20]\n",
      "pred: [599, 261, 599, 449, 253, 449, 1, 253, 449, 15, 1, 637, 1, 637, 1, 15, 5, 637, 68, 637, 1, 449, 15, 5, 253, 599, 15, 253]\n",
      "target [6, 76, 94, 675, 76, 19, 6, 6, 19, 46]\n",
      "pred: [1, 449, 68, 449, 1421, 1, 15, 120, 637, 599, 253, 599, 637, 1, 599, 120, 1, 253, 1, 1421, 15, 1, 599, 449, 1, 12, 253, 4379, 1, 599, 1, 12]\n",
      "target [17, 90, 62, 58, 477, 2, 902, 309, 224, 351]\n",
      "pred: [1, 449, 253, 1, 1421, 1, 253, 637, 1, 253, 449, 68, 1, 253, 15, 1, 637, 1, 449, 249, 68, 5, 68, 449, 261, 449, 15, 309]\n",
      "target [5, 1, 49, 253, 601, 319, 243, 723, 249, 332]\n",
      ">> Val: [30][1/1]\tTime 0.604 (0.604)\tAccu 0.000\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss()\n",
    "# criterion = nn.CTCLoss(zero_infinity=True)\n",
    "criterion = criterion.to(device)\n",
    "# define optimizer\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "converter = LabelConverter(args.alphabet, ignore_case=False)\n",
    "\n",
    "# define learning rate decay schedule\n",
    "# TODO: maybe pass as argument in future implementation?\n",
    "exp_decay = math.exp(-0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
    "# step_decay = 1\n",
    "# gamma_decay = 0.5\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_decay, gamma=gamma_decay)\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0.0\n",
    "accuracy = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    args.resume = os.path.join(args.directory, args.resume)\n",
    "    if os.path.isfile(args.resume):\n",
    "        # load checkpoint weights and update model and optimizer\n",
    "        print(\">> Loading checkpoint:\\n>> '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(\">>>> loaded checkpoint:\\n>>>> '{}' (epoch {})\".format(args.resume, start_epoch))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        # test only\n",
    "        if args.test_only:\n",
    "            print('>>>> Test model, using model at epoch: {}'.format(start_epoch))\n",
    "            accuracy = validate(dev_loader, model, start_epoch, converter)\n",
    "            print('>>>> Accuracy: {}'.format(accuracy))\n",
    "            #return\n",
    "        best_accuracy = checkpoint['best_accuracy']\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        # important not to forget scheduler updating\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay, last_epoch=start_epoch - 1)\n",
    "    else:\n",
    "        print(\">> No checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "for epoch in range(start_epoch, args.max_epoch):\n",
    "    # aujust learning rate for each epoch\n",
    "    scheduler.step()\n",
    "    # # debug printing to check if everything ok\n",
    "    # lr_feat = optimizer.param_groups[0]['lr']\n",
    "    # lr_pool = optimizer.param_groups[1]['lr']\n",
    "    # print('>> Features lr: {:.2e}; Pooling lr: {:.2e}'.format(lr_feat, lr_pool))\n",
    "\n",
    "    # train for one epoch on train set\n",
    "    loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    if (epoch + 1) % args.validate_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            accuracy = validate(dev_loader, model, epoch, converter)\n",
    "\n",
    "    # # evaluate on test datasets every test_freq epochs\n",
    "    # if (epoch + 1) % args.test_freq == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         test(args.test_datasets, model)\n",
    "\n",
    "    # remember best accuracy and save checkpoint\n",
    "    is_best = accuracy > 0.0 and accuracy >= best_accuracy\n",
    "    best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        save_checkpoint({\n",
    "            'arch': args.arch,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, args.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
